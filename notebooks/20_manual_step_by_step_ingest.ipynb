{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual ingest workflow, bypassing GUI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Login\n",
    "\n",
    "Either log in via a local config file (see [01_pipeline](./01_pipeline.ipynb)), or enter login information manually. If you are don't have your login information, contact the administrator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-11-07 17:52:27,768][INFO]: Connecting tobiasr@172.26.128.53:3306\n",
      "[2023-11-07 17:52:27,817][INFO]: Connected tobiasr@172.26.128.53:3306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.14.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# change to the upper level folder to detect dj_local_conf.json\n",
    "if os.path.basename(os.getcwd())=='notebooks': os.chdir('..')\n",
    "assert os.path.basename(os.getcwd())=='adamacs', (\"Please move to the main directory\")\n",
    "from adamacs.pipeline import subject, session, equipment, surgery, event, trial, imaging, behavior, model\n",
    "from adamacs.ingest import session as isess\n",
    "from adamacs.helpers import stack_helpers as sh\n",
    "from adamacs.ingest import behavior as ibe\n",
    "import pathlib\n",
    "from natsort import natsorted, ns\n",
    "import datajoint as dj\n",
    "from rspace_client.eln import eln\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "dj.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RSpace connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'OK', 'rspaceVersion': '1.89.2'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL=dj.config['custom'].get('rspace_URL')\n",
    "API_KEY=dj.config['custom'].get('rspace_API_key')\n",
    "api = eln.ELNClient(URL, API_KEY)\n",
    "api.get_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation\n",
    "Next, import from `adamacs.pipeline` to activate the relevant schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adamacs.utility import *\n",
    "# from adamacs.nbgui import *\n",
    "from adamacs.pipeline import subject, session, surgery, scan, equipment, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign easy names for relevant tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub, lab, protocol, line, mutation, user, project, subject_genotype, subject_death = (\n",
    "    subject.Subject(), subject.Lab(), subject.Protocol(), subject.Line(), \n",
    "    subject.Mutation(), subject.User(), subject.Project(), subject.SubjectGenotype(), \n",
    "    subject.SubjectDeath()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_session_dir_key_from_dir(directory):\n",
    "    return [path.split('/')[-1] for path in directory]\n",
    "     \n",
    "def get_scan_dir_key_from_dir(directory):\n",
    "    return [path.split('/')[-1] for path in directory]\n",
    "\n",
    "def get_session_key_from_dir(string):\n",
    "    result = [re.search(r'sess\\S+', item).group(0) for item in string]\n",
    "    return result\n",
    "\n",
    "def get_user_initials_from_dir(string):\n",
    "    result = [name[:2] for name in string]\n",
    "    return result\n",
    "\n",
    "def get_subject_key_from_dir(string):\n",
    "    result = [item.split(\"_\")[1] for item in string]\n",
    "    return result\n",
    "\n",
    "def get_date_key_from_dir(directory):\n",
    "    return directory.split(\"_\")[-1]\n",
    "\n",
    "def get_scan_key_from_dir(string):\n",
    "    result = [re.search(r'scan\\S+_', item).group(0)[:-1] for item in string]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JJ_ROS-1604_2023-11-02_scan9FKW82R3_sess9FKW82R3',\n",
       " 'JJ_ROS_1438_2022-11-22_scan9FF6TL96_sess9FF6TL96']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get content of user directory\n",
    "import fnmatch\n",
    "dataroot = dj.config['custom']['exp_root_data_dir'][0]\n",
    "# dirs_root = [d for d in os.listdir(dataroot) if os.path.isdir(os.path.join(dataroot, d)) and '_' in d]\n",
    "dirs_root = [d for d in os.listdir(dataroot) if os.path.isdir(os.path.join(dataroot, d)) and fnmatch.fnmatch(d, 'JJ*') and fnmatch.fnmatch(d, '*1-*')]\n",
    "sorted_dirs_root = natsorted(dirs_root, key=get_date_key_from_dir, reverse = True)\n",
    "sorted_dirs_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessi = \"sess9FKW82R3\"\n",
    "scansi = \"scan9FKW82R3\"\n",
    "# sessi = \"sess9FB2LN5C\"\n",
    "# scansi = \"scan9FB2LN5C\"\n",
    "\n",
    "# scan9FJ842C3\n",
    "# scan9FB2LN5C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session ingest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*project       project_descri\n",
      "+------------+ +------------+\n",
      "ATN            ATN-functional\n",
      "dummy          dummy         \n",
      "hpc-repstab    hpc-representa\n",
      "rsc-functop    rsc-functional\n",
      "rsc-hpc        rsc-hippocampa\n",
      "rsc-latent     rsc-contextual\n",
      "sc-lgn-actvis  sc-lgn-active-\n",
      "V1-oddball     v1-oddball-pre\n",
      "vc-lgn-repstab vc-lgn-represe\n",
      " (Total: 9)\n",
      "\n",
      "['bench2p' 'dummy' 'macroscope' 'mini2p_01' 'mini2p_02' 'mini2p_03'\n",
      " 'mini2p_04' 'mini2p_05']\n",
      "['ATN' 'Ctx' 'dCA1' 'DG' 'dummy' 'LGNV1' 'RSCa' 'RSCg' 'V1']\n",
      "[array([0, 1, 2, 3, 4, 5, 6]), array(['TR: Mini2p (new, non-rigid, individual scans, reg_tiff for movie, custom classifier)',\n",
      "       'TR: Mini2p (rigid, mini2p classifier, no concat, REGTIFF)',\n",
      "       'TR: Trondheim Mini2p (non-rigid, built-in classifier, scan_concat)',\n",
      "       'TR: Bench2p (non-rigid, custom classifier, reg_tiff for movie, scans individually)',\n",
      "       'TR: Bench2p (rigid, custom bench2p classifier, individual, SAVETIF)',\n",
      "       'TR: Mini2p (rigid, built-in classifier, individual)',\n",
      "       'TR: Mini2p (rigid, built-in classifier, SAMESITE_concat)'],\n",
      "      dtype=object)]\n",
      "['from_top_tracking-DJ' 'Head_orientation-NK-2023-07-17']\n"
     ]
    }
   ],
   "source": [
    "Project = project.fetch('project')\n",
    "Equipment = equipment.Equipment().fetch('scanner')\n",
    "Recording_Location = surgery.AnatomicalLocation().fetch('anatomical_location')\n",
    "s2pparm = imaging.ProcessingParamSet.fetch(\"paramset_idx\", \"paramset_desc\")\n",
    "DLCModels = model.Model.fetch(\"model_name\")\n",
    "\n",
    "print(project)\n",
    "print(Equipment)\n",
    "print(Recording_Location)\n",
    "print(s2pparm)\n",
    "print(DLCModels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ingest Session and Scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isess.ingest_session_scan(sessi, verbose=True, project_key=\"rsc-functop\", equipment_key=\"mini2p_01\", location_key=\"RSCa\", software_key='ScanImage')\n",
    "session.SessionSameSite.update1({'session_id': sessi, 'same_site_id': sessi})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.VideoRecording()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan.Scan * session.SessionSameSite * session.Session() * session.Equipment() & f'session_id = \"{sessi}\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = scan.ScanPath() & 'scan_id = \"' + scansi + '\"'\n",
    "dir_proc = query.fetch('path')[0]\n",
    "print(dir_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# push scan to ProcessingTask\n",
    "# TODO: handle multiscan concatenation from here?\n",
    "selected_s2pparms_index = 0\n",
    "imaging.ProcessingTask.insert1((sessi, scansi, selected_s2pparms_index, dir_proc, 'trigger'), skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imaging.ProcessingTask.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POPULATE!\n",
    "populate_settings = {'display_progress': True, 'suppress_errors': False, 'processes': 1}\n",
    "scan.ScanInfo.populate(**populate_settings) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest AUX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_setup_typestr = (scan.ScanInfo() & 'scan_id = \"' + scansi + '\"').fetch(\"userfunction_info\")[0]    \n",
    "print(aux_setup_typestr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibe.ingest_aux(sessi,scansi,verbose=True, aux_setup_type=aux_setup_typestr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run processing jobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.Processing.populate(**populate_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.Curation().create1_from_processing_task({'session_id': sessi, 'scan_id': scansi, \"paramset_idx\": selected_s2pparms_index, \"manual_curation\": 0})\n",
    "\n",
    "imaging.MotionCorrection.populate(**populate_settings)\n",
    "\n",
    "imaging.Segmentation.populate(**populate_settings)\n",
    "\n",
    "imaging.MaskClassification.populate(**populate_settings)\n",
    "\n",
    "imaging.Fluorescence.populate(**populate_settings)\n",
    "\n",
    "imaging.Activity.populate(**populate_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pose estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.Diagram(model) + dj.Diagram(equipment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - -\n",
      "DLC pose estimation: scan9FKW82R3\n"
     ]
    }
   ],
   "source": [
    "aux_setup_typestr = (scan.ScanInfo() & 'scan_id = \"' + scansi + '\"').fetch(\"userfunction_info\")[0]\n",
    "selected_DLCmodel = 'Head_orientation-NK-2023-07-17'\n",
    "print('- - - -')\n",
    "print('DLC pose estimation:', scansi)\n",
    "\n",
    "# insert TOP movie into model table\n",
    "scan_key = (scan.Scan & f'scan_id = \"{scansi}\"').fetch('KEY')[0] \n",
    "moviepath = str(list(pathlib.Path((scan.ScanPath() & scan_key).fetch(\"path\")[0]).glob(\"*top*.mp4*\"))[0])\n",
    "\n",
    "key = {'session_id': scan_key[\"session_id\"],\n",
    "    'recording_id': scan_key[\"scan_id\"], \n",
    "    'camera': \"mini2p1_top\", # Currently 'scanner' due to in equipment tables\n",
    "    }\n",
    "model.VideoRecording.insert1(key, skip_duplicates=True)\n",
    "\n",
    "key.update({'file_path': moviepath,\n",
    "            'file_id': 0})  #INCREMENT FILE_ID WITH CAM NUMBER?\n",
    "\n",
    "model.VideoRecording.File.insert1(key, ignore_extra_fields=True, skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    <style type=\"text/css\">\n",
       "        .Table{\n",
       "            border-collapse:collapse;\n",
       "        }\n",
       "        .Table th{\n",
       "            background: #A0A0A0; color: #ffffff; padding:4px; border:#f0e0e0 1px solid;\n",
       "            font-weight: normal; font-family: monospace; font-size: 100%;\n",
       "        }\n",
       "        .Table td{\n",
       "            padding:4px; border:#f0e0e0 1px solid; font-size:100%;\n",
       "        }\n",
       "        .Table tr:nth-child(odd){\n",
       "            background: #ffffff;\n",
       "            color: #000000;\n",
       "        }\n",
       "        .Table tr:nth-child(even){\n",
       "            background: #f3f1ff;\n",
       "            color: #000000;\n",
       "        }\n",
       "        /* Tooltip container */\n",
       "        .djtooltip {\n",
       "        }\n",
       "        /* Tooltip text */\n",
       "        .djtooltip .djtooltiptext {\n",
       "            visibility: hidden;\n",
       "            width: 120px;\n",
       "            background-color: black;\n",
       "            color: #fff;\n",
       "            text-align: center;\n",
       "            padding: 5px 0;\n",
       "            border-radius: 6px;\n",
       "            /* Position the tooltip text - see examples below! */\n",
       "            position: absolute;\n",
       "            z-index: 1;\n",
       "        }\n",
       "        #primary {\n",
       "            font-weight: bold;\n",
       "            color: black;\n",
       "        }\n",
       "        #nonprimary {\n",
       "            font-weight: normal;\n",
       "            color: white;\n",
       "        }\n",
       "\n",
       "        /* Show the tooltip text when you mouse over the tooltip container */\n",
       "        .djtooltip:hover .djtooltiptext {\n",
       "            visibility: visible;\n",
       "        }\n",
       "    </style>\n",
       "    \n",
       "    \n",
       "        <div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "        <table border=\"1\" class=\"Table\">\n",
       "            <thead> <tr style=\"text-align: right;\"> <th> <div class=\"djtooltip\">\n",
       "                            <p id=\"primary\">session_id</p>\n",
       "                            <span class=\"djtooltiptext\"></span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"primary\">recording_id</p>\n",
       "                            <span class=\"djtooltiptext\"></span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"primary\">file_id</p>\n",
       "                            <span class=\"djtooltiptext\"></span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">file_path</p>\n",
       "                            <span class=\"djtooltiptext\">filepath of video, relative to root data directory</span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">camera</p>\n",
       "                            <span class=\"djtooltiptext\"></span>\n",
       "                        </div> </th> </tr> </thead>\n",
       "            <tbody> <tr> <td>sess9FKW82R3</td>\n",
       "<td>scan9FKW82R3</td>\n",
       "<td>0</td>\n",
       "<td>/datajoint-data/data/tobiasr/JJ_ROS-1604_2023-11-02_scan9FKW82R3_sess9FKW82R3/scan9FKW82R3_mini2p1_top_video_2023-11-02T15_40_02.mp4</td>\n",
       "<td>mini2p1_top</td> </tr> </tbody>\n",
       "        </table>\n",
       "        \n",
       "        <p>Total: 1</p></div>\n",
       "        "
      ],
      "text/plain": [
       "*session_id    *recording_id  *file_id    file_path      camera        \n",
       "+------------+ +------------+ +---------+ +------------+ +------------+\n",
       "sess9FKW82R3   scan9FKW82R3   0           /datajoint-dat mini2p1_top   \n",
       " (Total: 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.VideoRecording.File * model.VideoRecording() &  'recording_id = \"' + scansi + '\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'session_id': 'sess9FKW82R3',\n",
       " 'recording_id': 'scan9FKW82R3',\n",
       " 'model_name': 'Head_orientation-NK-2023-07-17',\n",
       " 'task_mode': 'trigger'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key =  (model.VideoRecording & f'recording_id=\"{scansi}\"').fetch1('KEY')\n",
    "key.update({'model_name': selected_DLCmodel, 'task_mode': 'trigger'}) \n",
    "key      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT pose estimation task\n",
    "\n",
    "model.PoseEstimationTask.insert_estimation_task(key, key[\"model_name\"], analyze_videos_params={'save_as_csv':True, 'dynamic':(True,.5,60)}) # dynamic cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    <style type=\"text/css\">\n",
       "        .Table{\n",
       "            border-collapse:collapse;\n",
       "        }\n",
       "        .Table th{\n",
       "            background: #A0A0A0; color: #ffffff; padding:4px; border:#f0e0e0 1px solid;\n",
       "            font-weight: normal; font-family: monospace; font-size: 100%;\n",
       "        }\n",
       "        .Table td{\n",
       "            padding:4px; border:#f0e0e0 1px solid; font-size:100%;\n",
       "        }\n",
       "        .Table tr:nth-child(odd){\n",
       "            background: #ffffff;\n",
       "            color: #000000;\n",
       "        }\n",
       "        .Table tr:nth-child(even){\n",
       "            background: #f3f1ff;\n",
       "            color: #000000;\n",
       "        }\n",
       "        /* Tooltip container */\n",
       "        .djtooltip {\n",
       "        }\n",
       "        /* Tooltip text */\n",
       "        .djtooltip .djtooltiptext {\n",
       "            visibility: hidden;\n",
       "            width: 120px;\n",
       "            background-color: black;\n",
       "            color: #fff;\n",
       "            text-align: center;\n",
       "            padding: 5px 0;\n",
       "            border-radius: 6px;\n",
       "            /* Position the tooltip text - see examples below! */\n",
       "            position: absolute;\n",
       "            z-index: 1;\n",
       "        }\n",
       "        #primary {\n",
       "            font-weight: bold;\n",
       "            color: black;\n",
       "        }\n",
       "        #nonprimary {\n",
       "            font-weight: normal;\n",
       "            color: white;\n",
       "        }\n",
       "\n",
       "        /* Show the tooltip text when you mouse over the tooltip container */\n",
       "        .djtooltip:hover .djtooltiptext {\n",
       "            visibility: visible;\n",
       "        }\n",
       "    </style>\n",
       "    \n",
       "    <b></b>\n",
       "        <div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "        <table border=\"1\" class=\"Table\">\n",
       "            <thead> <tr style=\"text-align: right;\"> <th> <div class=\"djtooltip\">\n",
       "                            <p id=\"primary\">session_id</p>\n",
       "                            <span class=\"djtooltiptext\"></span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"primary\">recording_id</p>\n",
       "                            <span class=\"djtooltiptext\"></span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"primary\">model_name</p>\n",
       "                            <span class=\"djtooltiptext\">User-friendly model name</span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">task_mode</p>\n",
       "                            <span class=\"djtooltiptext\">load results or trigger computation</span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">pose_estimation_output_dir</p>\n",
       "                            <span class=\"djtooltiptext\">output dir relative to the root dir</span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">pose_estimation_params</p>\n",
       "                            <span class=\"djtooltiptext\">analyze_videos params, if not default</span>\n",
       "                        </div> </th> </tr> </thead>\n",
       "            <tbody> <tr> <td>sess9FB2LN5C</td>\n",
       "<td>scan9FB2LN5C</td>\n",
       "<td>Head_orientation-NK-2023-07-17</td>\n",
       "<td>trigger</td>\n",
       "<td>/datajoint-data/data/tobiasr/DB_WEZ-8701_2022-03-18_scan9FB2LN5C_sess9FB2LN5C/device_mini2p1_top_recording_scan9FB2LN5C_model_Head_orientation-NK-2023-07-17</td>\n",
       "<td>=BLOB=</td></tr><tr><td>sess9FKW82R3</td>\n",
       "<td>scan9FKW82R3</td>\n",
       "<td>Head_orientation-NK-2023-07-17</td>\n",
       "<td>trigger</td>\n",
       "<td>/datajoint-data/data/tobiasr/JJ_ROS-1604_2023-11-02_scan9FKW82R3_sess9FKW82R3/device_mini2p1_top_recording_scan9FKW82R3_model_Head_orientation-NK-2023-07-17</td>\n",
       "<td>=BLOB=</td> </tr> </tbody>\n",
       "        </table>\n",
       "        \n",
       "        <p>Total: 2</p></div>\n",
       "        "
      ],
      "text/plain": [
       "*session_id    *recording_id  *model_name    task_mode     pose_estimatio pose_estim\n",
       "+------------+ +------------+ +------------+ +-----------+ +------------+ +--------+\n",
       "sess9FB2LN5C   scan9FB2LN5C   Head_orientati trigger       /datajoint-dat =BLOB=    \n",
       "sess9FKW82R3   scan9FKW82R3   Head_orientati trigger       /datajoint-dat =BLOB=    \n",
       " (Total: 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.PoseEstimationTask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 17:55:19.645590: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-07 17:55:19.819224: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/tobiasr/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-11-07 17:55:19.819255: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-11-07 17:55:19.853301: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-07 17:55:20.676453: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/tobiasr/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-11-07 17:55:20.676515: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/tobiasr/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-11-07 17:55:20.676523: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 2.3.5...\n",
      "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n",
      "Using snapshot-90000 for model /datajoint-data/models/tobiasr/NK_DLC_tracking/Head_orientation-NK-2023-07-17/dlc-models/iteration-0/Head_orientationJul17-trainset95shuffle1\n",
      "Starting analysis in dynamic cropping mode with parameters: (True, 0.5, 100)\n",
      "Switching batchsize to 1, num_outputs (per animal) to 1 and TFGPUinference to False (all these features are not supported in this mode).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tobiasr/miniconda3/envs/dj_pure/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "2023-11-07 17:55:24.941473: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/tobiasr/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-11-07 17:55:24.941562: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-11-07 17:55:24.941585: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tatchu3): /proc/driver/nvidia/version does not exist\n",
      "2023-11-07 17:55:24.941968: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-07 17:55:24.977012: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /datajoint-data/data/tobiasr/DB_WEZ-8701_2022-03-18_scan9FB2LN5C_sess9FB2LN5C/scan9FB2LN5C_top_video_2022-03-18T16_55_33.mp4\n",
      "Loading  /datajoint-data/data/tobiasr/DB_WEZ-8701_2022-03-18_scan9FB2LN5C_sess9FB2LN5C/scan9FB2LN5C_top_video_2022-03-18T16_55_33.mp4\n",
      "Duration of video [s]:  300.0 , recorded with  60.0 fps!\n",
      "Overall # of frames:  18000  found with (before cropping) frame dimensions:  500 500\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 360/18000 [00:21<17:52, 16.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No meta file (.pickle) found in: /datajoint-data/data/tobiasr/DB_WEZ-8701_2022-03-18_scan9FB2LN5C_sess9FB2LN5C/device_mini2p1_top_recording_scan9FB2LN5C_model_Head_orientation-NK-2023-07-17",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# run pose estimation\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPoseEstimation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dj_pure/lib/python3.8/site-packages/datajoint/autopopulate.py:241\u001b[0m, in \u001b[0;36mAutoPopulate.populate\u001b[0;34m(self, suppress_errors, return_exception_objects, reserve_jobs, order, limit, max_calls, display_progress, processes, make_kwargs, *restrictions)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m processes \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m    239\u001b[0m         tqdm(keys, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m display_progress \u001b[38;5;28;01melse\u001b[39;00m keys\n\u001b[1;32m    240\u001b[0m     ):\n\u001b[0;32m--> 241\u001b[0m         error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_populate1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopulate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    243\u001b[0m             error_list\u001b[38;5;241m.\u001b[39mappend(error)\n",
      "File \u001b[0;32m~/miniconda3/envs/dj_pure/lib/python3.8/site-packages/datajoint/autopopulate.py:292\u001b[0m, in \u001b[0;36mAutoPopulate._populate1\u001b[0;34m(self, key, jobs, suppress_errors, return_exception_objects, make_kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_insert \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 292\u001b[0m     \u001b[43mmake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmake_kwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mSystemExit\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dj_pure/lib/python3.8/site-packages/element_deeplabcut/model.py:735\u001b[0m, in \u001b[0;36mPoseEstimation.make\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    722\u001b[0m     analyze_video_params \u001b[38;5;241m=\u001b[39m (PoseEstimationTask \u001b[38;5;241m&\u001b[39m key)\u001b[38;5;241m.\u001b[39mfetch1(\n\u001b[1;32m    723\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpose_estimation_params\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    724\u001b[0m     ) \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m    726\u001b[0m     dlc_reader\u001b[38;5;241m.\u001b[39mdo_pose_estimation(\n\u001b[1;32m    727\u001b[0m         key,\n\u001b[1;32m    728\u001b[0m         video_filepaths,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39manalyze_video_params,\n\u001b[1;32m    733\u001b[0m     )\n\u001b[0;32m--> 735\u001b[0m dlc_result \u001b[38;5;241m=\u001b[39m \u001b[43mdlc_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPoseEstimation\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    736\u001b[0m creation_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mfromtimestamp(dlc_result\u001b[38;5;241m.\u001b[39mcreation_time)\u001b[38;5;241m.\u001b[39mstrftime(\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    738\u001b[0m )\n\u001b[1;32m    740\u001b[0m body_parts \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    741\u001b[0m     {\n\u001b[1;32m    742\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkey,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m dlc_result\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    751\u001b[0m ]\n",
      "File \u001b[0;32m~/miniconda3/envs/dj_pure/lib/python3.8/site-packages/element_deeplabcut/readers/dlc_reader.py:43\u001b[0m, in \u001b[0;36mPoseEstimation.__init__\u001b[0;34m(self, dlc_dir, pkl_path, h5_path, yml_path, filename_prefix)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpkl_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdlc_dir\u001b[38;5;241m.\u001b[39mrglob(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m*meta.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m     )\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpkl_paths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 43\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m     44\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo meta file (.pickle) found in: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdlc_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     45\u001b[0m         )\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     pkl_path \u001b[38;5;241m=\u001b[39m Path(pkl_path)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No meta file (.pickle) found in: /datajoint-data/data/tobiasr/DB_WEZ-8701_2022-03-18_scan9FB2LN5C_sess9FB2LN5C/device_mini2p1_top_recording_scan9FB2LN5C_model_Head_orientation-NK-2023-07-17"
     ]
    }
   ],
   "source": [
    "# run pose estimation\n",
    "model.PoseEstimation.populate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning. Use with caution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject.Subject.delete()\n",
    "# session.Session.delete()\n",
    "# imaging.Processing.delete()\n",
    "# imaging.Curation.delete()\n",
    "# event.Event.delete()\n",
    "# event.BehaviorRecording.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (session.Session & \"session_id LIKE 'sess9FKW82R3%'\").delete()\n",
    "(imaging.ProcessingTask & \"session_id LIKE 'sess9FKNBQCS%'\").delete()\n",
    "# (subject.Subject & \"subject = 'ROS-1571'\").delete()\n",
    "# # subject.Subject.delete()\n",
    "# # session.Session.delete()\n",
    "# # imaging.Processing.delete()\n",
    "# # imaging.Curation.delete()\n",
    "# # event.Event.delete()\n",
    "# # event.BehaviorRecording.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session.Session.drop()\n",
    "# scan.Scan.drop()\n",
    "# imaging.Processing.drop()\n",
    "# imaging.Curation.drop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datajoint-DLCbackup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

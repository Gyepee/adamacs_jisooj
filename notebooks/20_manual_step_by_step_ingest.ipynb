{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual ingest workflow, bypassing GUI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Login\n",
    "\n",
    "Either log in via a local config file (see [01_pipeline](./01_pipeline.ipynb)), or enter login information manually. If you are don't have your login information, contact the administrator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-11-15 09:22:38,557][INFO]: Connecting tobiasr@172.26.128.53:3306\n",
      "[2023-11-15 09:22:38,607][INFO]: Connected tobiasr@172.26.128.53:3306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.14.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# change to the upper level folder to detect dj_local_conf.json\n",
    "if os.path.basename(os.getcwd())=='notebooks': os.chdir('..')\n",
    "assert os.path.basename(os.getcwd())=='adamacs', (\"Please move to the main directory\")\n",
    "from adamacs.pipeline import subject, session, equipment, surgery, event, trial, imaging, behavior, model\n",
    "from adamacs.ingest import session as isess\n",
    "from adamacs.helpers import stack_helpers as sh\n",
    "from adamacs.ingest import behavior as ibe\n",
    "import pathlib\n",
    "from natsort import natsorted, ns\n",
    "import datajoint as dj\n",
    "from rspace_client.eln import eln\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "dj.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RSpace connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'OK', 'rspaceVersion': '1.93.0'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL=dj.config['custom'].get('rspace_URL')\n",
    "API_KEY=dj.config['custom'].get('rspace_API_key')\n",
    "api = eln.ELNClient(URL, API_KEY)\n",
    "api.get_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation\n",
    "Next, import from `adamacs.pipeline` to activate the relevant schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adamacs.utility import *\n",
    "# from adamacs.nbgui import *\n",
    "from adamacs.pipeline import subject, session, surgery, scan, equipment, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign easy names for relevant tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub, lab, protocol, line, mutation, user, project, subject_genotype, subject_death = (\n",
    "    subject.Subject(), subject.Lab(), subject.Protocol(), subject.Line(), \n",
    "    subject.Mutation(), subject.User(), subject.Project(), subject.SubjectGenotype(), \n",
    "    subject.SubjectDeath()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_session_dir_key_from_dir(directory):\n",
    "    return [path.split('/')[-1] for path in directory]\n",
    "     \n",
    "def get_scan_dir_key_from_dir(directory):\n",
    "    return [path.split('/')[-1] for path in directory]\n",
    "\n",
    "def get_session_key_from_dir(string):\n",
    "    result = [re.search(r'sess\\S+', item).group(0) for item in string]\n",
    "    return result\n",
    "\n",
    "def get_user_initials_from_dir(string):\n",
    "    result = [name[:2] for name in string]\n",
    "    return result\n",
    "\n",
    "def get_subject_key_from_dir(string):\n",
    "    result = [item.split(\"_\")[1] for item in string]\n",
    "    return result\n",
    "\n",
    "def get_date_key_from_dir(directory):\n",
    "    return directory.split(\"_\")[-1]\n",
    "\n",
    "def get_scan_key_from_dir(string):\n",
    "    result = [re.search(r'scan\\S+_', item).group(0)[:-1] for item in string]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JJ_ROS-1627_2023-11-03_scan9FKWTLNS_sess9FKWTLNS',\n",
       " 'JJ_ROS-1627_2023-11-03_scan9FKWT95S_sess9FKWT95S',\n",
       " 'JJ_ROS-1627_2023-11-03_scan9FKWT2RT_sess9FKWT2RT',\n",
       " 'JJ_ROS-1604_2023-11-02_scan9FKW82R3_sess9FKW82R3',\n",
       " 'JJ_ROS_1438_2022-11-22_scan9FF6TL96_sess9FF6TL96']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get content of user directory\n",
    "import fnmatch\n",
    "dataroot = dj.config['custom']['exp_root_data_dir'][0]\n",
    "# dirs_root = [d for d in os.listdir(dataroot) if os.path.isdir(os.path.join(dataroot, d)) and '_' in d]\n",
    "dirs_root = [d for d in os.listdir(dataroot) if os.path.isdir(os.path.join(dataroot, d)) and fnmatch.fnmatch(d, 'JJ*') and fnmatch.fnmatch(d, '*11-*')]\n",
    "sorted_dirs_root = natsorted(dirs_root, key=get_date_key_from_dir, reverse = True)\n",
    "sorted_dirs_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mini2p1_openfield\n",
      "/datajoint-data/data/tobiasr/JJ_ROS-1627_2023-11-03_scan9FKWT95S_sess9FKWT95S\n"
     ]
    }
   ],
   "source": [
    "# sessi = \"sess9FKW82R3\"\n",
    "# scansi = \"scan9FKW82R3\"\n",
    "# sessi = \"sess9FKWTLNS\"\n",
    "# scansi = \"scan9FKWTLNS\"\n",
    "\n",
    "# sessi = \"sess9FB2LN5C\"\n",
    "# scansi = \"scan9FB2LN5C\"\n",
    "\n",
    "# scan9FJ842C3\n",
    "# scan9FB2LN5C\n",
    "# scan_key\n",
    "\n",
    "scansi = \"scan9FKWT95S\"\n",
    "\n",
    "scan_key = (scan.Scan & f'scan_id = \"{scansi}\"').fetch('KEY')[0]\n",
    "curation_key = (imaging.Curation & scan_key & 'curation_id=1').fetch1('KEY')\n",
    "sessi = (scan.Scan & f'scan_id = \"{scansi}\"').fetch('session_id')[0]\n",
    "session_key = (session.Session & f'session_id = \"{sessi}\"').fetch('KEY')[0]\n",
    "aux_setup_typestr = (scan.ScanInfo() & scan_key).fetch(\"userfunction_info\")[0] # check setup type (not needed)\n",
    "print(aux_setup_typestr)\n",
    "print((scan.ScanPath & scan_key).fetch(\"path\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session ingest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project\n",
      "*project       project_descri\n",
      "+------------+ +------------+\n",
      "ATN            ATN-functional\n",
      "dummy          dummy         \n",
      "hpc-repstab    hpc-representa\n",
      "rsc-functop    rsc-functional\n",
      "rsc-hpc        rsc-hippocampa\n",
      "rsc-latent     rsc-contextual\n",
      "sc-lgn-actvis  sc-lgn-active-\n",
      "V1-oddball     v1-oddball-pre\n",
      "vc-lgn-repstab vc-lgn-represe\n",
      " (Total: 9)\n",
      "\n",
      "Equipment\n",
      "['bench2p' 'dummy' 'macroscope' 'mini2p_01' 'mini2p_02' 'mini2p_03'\n",
      " 'mini2p_04' 'mini2p_05']\n",
      "Recording_Location\n",
      "['ATN' 'Ctx' 'dCA1' 'DG' 'dummy' 'LGNV1' 'RSCa' 'RSCg' 'V1']\n",
      "s2pparm\n",
      "[array([0, 1, 2, 3, 4, 5, 6]), array(['TR: Mini2p (new, non-rigid, individual scans, reg_tiff for movie, custom classifier)',\n",
      "       'TR: Mini2p (rigid, mini2p classifier, no concat, REGTIFF)',\n",
      "       'TR: Trondheim Mini2p (non-rigid, built-in classifier, scan_concat)',\n",
      "       'TR: Bench2p (non-rigid, custom classifier, reg_tiff for movie, scans individually)',\n",
      "       'TR: Bench2p (rigid, custom bench2p classifier, individual, SAVETIF)',\n",
      "       'TR: Mini2p (rigid, built-in classifier, individual)',\n",
      "       'TR: Mini2p (rigid, built-in classifier, SAMESITE_concat)'],\n",
      "      dtype=object)]\n",
      "DLCModels\n",
      "['Head_orientation-NK-2023-07-17' 'Topcam_2bin_without_scope'\n",
      " 'Topcam_2bin_with_scope']\n"
     ]
    }
   ],
   "source": [
    "Project = project.fetch('project')\n",
    "Equipment = equipment.Equipment().fetch('scanner')\n",
    "Recording_Location = surgery.AnatomicalLocation().fetch('anatomical_location')\n",
    "s2pparm = imaging.ProcessingParamSet.fetch(\"paramset_idx\", \"paramset_desc\")\n",
    "DLCModels = model.Model.fetch(\"model_name\")\n",
    "\n",
    "print(\"Project\")\n",
    "print(project)\n",
    "\n",
    "print(\"Equipment\")\n",
    "print(Equipment)\n",
    "\n",
    "print(\"Recording_Location\")\n",
    "print(Recording_Location)\n",
    "\n",
    "print(\"s2pparm\")\n",
    "print(s2pparm)\n",
    "\n",
    "print(\"DLCModels\")\n",
    "print(DLCModels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingest Session and Scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isess.ingest_session_scan(sessi, verbose=True, project_key=\"rsc-functop\", equipment_key=\"mini2p_01\", location_key=\"RSCa\", software_key='ScanImage')\n",
    "session.SessionSameSite.update1({'session_id': sessi, 'same_site_id': sessi})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/datajoint-data/data/tobiasr/JJ_ROS-1627_2023-11-03_scan9FKWTLNS_sess9FKWTLNS\n"
     ]
    }
   ],
   "source": [
    "query = scan.ScanPath() & 'scan_id = \"' + scansi + '\"'\n",
    "dir_proc = query.fetch('path')[0]\n",
    "print(dir_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POPULATE!\n",
    "populate_settings = {'display_progress': True, 'suppress_errors': False, 'processes': 1}\n",
    "scan.ScanInfo.populate(**populate_settings) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scan.Scan * scan.ScanInfo * session.SessionSameSite * session.Session() & f'session_id = \"{sessi}\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# push scan to ProcessingTask\n",
    "# TODO: handle multiscan concatenation from here?\n",
    "selected_s2pparms_index = 0\n",
    "imaging.ProcessingTask.insert1((sessi, scansi, selected_s2pparms_index, dir_proc, 'trigger'), skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.ProcessingTask()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest AUX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_setup_typestr = (scan.ScanInfo() & 'scan_id = \"' + scansi + '\"').fetch(\"userfunction_info\")[0]    \n",
    "print(aux_setup_typestr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibe.ingest_aux(sessi,scansi,verbose=True, aux_setup_type=aux_setup_typestr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(event.Event & 'scan_id = \"' + scansi + '\"' & 'event_type LIKE \"%frames%\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_differences = np.diff((event.Event & 'scan_id = \"' + scansi + '\"' & 'event_type LIKE \"%reward%\"').fetch(\"event_start_time\"))\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.hist(time_differences, bins=range(min(time_differences.astype(int)), max(time_differences.astype(int)) + 10, 1), edgecolor='black')\n",
    "# plt.title('Histogram of Time Differences Between Consecutive Events')\n",
    "# plt.xlabel('Time Difference (seconds)')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest BPOD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibe.ingest_bpod(sessi,scansi,verbose=False, aux_setup_type=aux_setup_typestr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get BPOD object to play around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adamacs.paths import get_imaging_root_data_dir, get_experiment_root_data_dir\n",
    "from adamacs.ingest import bpod\n",
    "from element_interface.utils import find_full_path\n",
    "\n",
    "scan_key = (scan.Scan & f'scan_id = \"{scansi}\"').fetch('KEY')[0]\n",
    "bpod_path_relative = (scan.ScanPath & scan_key).fetch(\"path\")[0]\n",
    "\n",
    "bpod_path_full = list(find_full_path(\n",
    "        get_experiment_root_data_dir(), bpod_path_relative\n",
    "        ).glob(\"*mat\"))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpod_object = bpod.Bpodfile(bpod_path_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpod_object.session_data[\"Info\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpod_object.session_data[\"MousePos\"]['PreStimDLC_live'][10]['right_ear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpod_object.trial_data[0]['Events']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trials = bpod_object.trial_data\n",
    "BNC1Low_events = [(i, trial['Events'].get('BNC1Low')) for i, trial in enumerate(trials) if 'BNC1Low' in trial['Events']]\n",
    "print(BNC1Low_events)\n",
    "# BNC1Low_events[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trials[0]['Events']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpod_object.session_data[\"RawEvents\"][\"Trial\"][1][\"Events\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpod_object.session_data[\"RawEvents\"][\"Trial\"][0][\"Events\"][\"BNC1High\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpod_object.session_data[\"RawEvents\"][\"Trial\"][-2][\"Events\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BNC1Low_events = [(i, event.get('BNC1Low')) for i, event in enumerate(events) if 'BNC1Low' in event]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BNC1Low_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpod_object.session_data[\"StimPos\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpod_object.trial_data[34]['Events']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = bpod_object.trial_data\n",
    "SoftCode15_events = [(i, trial['Events'].get('SoftCode15')) for i, trial in enumerate(trials) if 'SoftCode15' in trial['Events']] # get all trials that have a BNC1Low event. Returns a list of tuples (trial number, event time)\n",
    "\n",
    "SoftCode15_events_times = [x[1] for x in SoftCode15_events]\n",
    "\n",
    "plt.hist(SoftCode15_events_times, bins=1000, edgecolor='black')\n",
    "plt.xlim([0, 1])\n",
    "plt.title('Histogram of softcode 15 event-to-trial-beginning time')\n",
    "plt.xlabel('[s]')\n",
    "plt.ylabel('Frequency')\n",
    "# plt.xlim([0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = bpod_object.trial_data\n",
    "SoftCode10_events = [(i, trial['Events'].get('SoftCode10')) for i, trial in enumerate(trials) if 'SoftCode10' in trial['Events']] # get all trials that have a BNC1Low event. Returns a list of tuples (trial number, event time)\n",
    "\n",
    "SoftCode10_events_times = [x[1] for x in SoftCode10_events]\n",
    "\n",
    "plt.hist(SoftCode10_events_times, edgecolor='black')\n",
    "plt.xlim([0, 1])\n",
    "plt.title('Histogram of softcode 10 event-to-trial-beginning time')\n",
    "plt.xlabel('[s]')\n",
    "plt.ylabel('Frequency')\n",
    "# plt.xlim([0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SoftCode10_events_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the times of the tone onsets\n",
    "aux_tone = (event.Event & 'scan_id = \"' + scansi + '\"' & 'event_type LIKE \"%vis%\"').fetch(\"event_start_time\")\n",
    "# create a time series of ones, using the same length as the tone onsets\n",
    "onesfive = np.ones_like(aux_tone) -.5\n",
    "# plot the time series of ones vs the tone onsets\n",
    "axs[0].scatter(aux_tone, onesfive)\n",
    "\n",
    "# get the times of the trial start events\n",
    "bpod_trial = bpod_object.session_data[\"TrialStartTimestamp\"]\n",
    "# create a time series of ones, using the same length as the trial start events\n",
    "ones = np.ones_like(bpod_trial)\n",
    "# plot the time series of ones vs the trial start events\n",
    "axs[1].scatter(bpod_trial, ones)\n",
    "\n",
    "# get the times of the visual cue onsets\n",
    "aux_vis = (event.Event & 'scan_id = \"' + scansi + '\"' & 'event_type LIKE \"%vis%\"').fetch(\"event_start_time\")\n",
    "# create a time series of ones, using the same length as the visual cue onsets\n",
    "onesvis = np.ones_like(aux_vis) -1\n",
    "axs[2].scatter(aux_vis, onesvis)\n",
    "\n",
    "# get the times of the auditory cue onsets\n",
    "aux_aud = (event.Event & 'scan_id = \"' + scansi + '\"' & 'event_type LIKE \"%aud%\"').fetch(\"event_start_time\")\n",
    "# create a time series of ones, using the same length as the auditory cue onsets\n",
    "onesaud = np.ones_like(aux_aud) -2\n",
    "axs[2].scatter(aux_aud, onesaud)\n",
    "\n",
    "# get the times of the reward onsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_timeseries_and_find_non_matching_events(time_series_1, time_series_2):\n",
    "    # Create event markers for each timeseries\n",
    "    events_1 = np.zeros(int(np.ceil(max(time_series_1))))\n",
    "    events_2 = np.zeros(int(np.ceil(max(time_series_2))))\n",
    "\n",
    "    # Mark the events\n",
    "    for event in time_series_1:\n",
    "        events_1[int(event)] = 1\n",
    "    for event in time_series_2:\n",
    "        events_2[int(event)] = 1\n",
    "\n",
    "    # Pad the shorter timeseries with zeros to make them the same length\n",
    "    if len(events_1) > len(events_2):\n",
    "        events_2 = np.pad(events_2, (0, len(events_1) - len(events_2)), 'constant')\n",
    "    elif len(events_2) > len(events_1):\n",
    "        events_1 = np.pad(events_1, (0, len(events_2) - len(events_1)), 'constant')\n",
    "\n",
    "    # Perform cross-correlation\n",
    "    correlation = correlate(events_1, events_2, mode='full')\n",
    "    lag = np.argmax(correlation) - (len(events_2) - 1)\n",
    "\n",
    "    # Shift the second series according to the lag\n",
    "    aligned_series_2 = np.roll(events_2, -lag)[:len(events_1)]\n",
    "\n",
    "    # Find the indices where events do not match\n",
    "    non_matching_indices = np.where((events_1 == 1) & (aligned_series_2 == 0))[0]\n",
    "\n",
    "    # Convert indices back to times\n",
    "    non_matching_times = time_series_1[np.isin(time_series_1, non_matching_indices)]\n",
    "\n",
    "    return non_matching_indices, non_matching_times, lag\n",
    "\n",
    "# Align the two timeseries and find non-matching events\n",
    "non_matching_indices, non_matching_times, alignment_lag = align_timeseries_and_find_non_matching_events(bpod_trial, aux_tone)\n",
    "\n",
    "non_matching_indices, non_matching_times, alignment_lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_tone - aux_tone[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpod_trial-bpod_trial[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_matching_times, alignment_lag = align_timeseries_and_find_non_matching_events(bpod_trial, aux_tone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import correlate\n",
    "\n",
    "def align_timeseries(series1, series2):\n",
    "    \"\"\"\n",
    "    This function aligns two timeseries data and finds non-matching events.\n",
    "\n",
    "    :param series1: First timeseries data as a numpy array.\n",
    "    :param series2: Second timeseries data as a numpy array.\n",
    "    :return: Indices of non-matching events in series1.\n",
    "    \"\"\"\n",
    "\n",
    "    # Perform cross-correlation\n",
    "    correlation = correlate(series1, series2, mode='full')\n",
    "    # Find the lag that maximizes the cross-correlation\n",
    "    lag = np.argmax(correlation) - (len(series2) - 1)\n",
    "\n",
    "    # Align the series by shifting series2\n",
    "    aligned_series2 = np.roll(series2, -lag)\n",
    "\n",
    "    # Find non-matching events (where one series has an event and the other does not)\n",
    "    non_matching_events = np.where((series1 != 0) != (aligned_series2[:len(series1)] != 0))[0]\n",
    "\n",
    "    return non_matching_events, lag, aligned_series2\n",
    "\n",
    "# Call the alignment function\n",
    "non_matching_indices, calculated_lag, aligned_series2 = align_timeseries(bpod_trial, aux_tone)\n",
    "\n",
    "print(f\"Non-matching event indices in series1: {non_matching_indices}\")\n",
    "print(f\"Lag for alignment: {calculated_lag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_tone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpod_trial = bpod_object.session_data[\"TrialStartTimestamp\"]\n",
    "bpod_trial = np.concatenate(([1], bpod_trial))\n",
    "ones = np.ones_like(bpod_trial)\n",
    "\n",
    "ones2 = np.ones_like(aligned_series2)\n",
    "\n",
    "aux_tone = (event.Event & 'scan_id = \"' + scansi + '\"' & 'event_type LIKE \"%vis%\"').fetch(\"event_start_time\")\n",
    "onesfive = np.ones_like(aux_tone) -.5\n",
    "\n",
    "fig, axs = plt.subplots(2,figsize=(20, 6))\n",
    "axs[0].scatter(aux_tone, onesfive+0.5)\n",
    "axs[1].scatter(bpod_trial, ones)\n",
    "axs[0].scatter(aligned_series2, ones2, c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtw import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the alignment\n",
    "alignment = dtw(aux_tone, bpod_trial, keep_internals=True)\n",
    "\n",
    "# Plot the original time series\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(aux_tone, label='aux_tone')\n",
    "plt.plot(bpod_trial, label='bpod_trial')\n",
    "plt.legend()\n",
    "\n",
    "# Plot the warping path\n",
    "plt.subplot(3, 1, 2)\n",
    "alignment.plot(type=\"twoway\",offset=-2)\n",
    "\n",
    "# Plot the aligned time series\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(aux_tone[alignment.index1], label='aligned aux_tone')\n",
    "plt.plot(bpod_trial[alignment.index2], label='aligned bpod_trial')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dtw(s, t, window):\n",
    "    n, m = len(s), len(t)\n",
    "    w = np.max([window, abs(n-m)])\n",
    "    dtw_matrix = np.zeros((n+1, m+1))\n",
    "    \n",
    "    for i in range(n+1):\n",
    "        for j in range(m+1):\n",
    "            dtw_matrix[i, j] = np.inf\n",
    "    dtw_matrix[0, 0] = 0\n",
    "    \n",
    "    for i in range(1, n+1):\n",
    "        for j in range(np.max([1, i-w]), np.min([m, i+w])+1):\n",
    "            dtw_matrix[i, j] = 0\n",
    "    \n",
    "    for i in range(1, n+1):\n",
    "        for j in range(np.max([1, i-w]), np.min([m, i+w])+1):\n",
    "            cost = abs(s[i-1] - t[j-1])\n",
    "            # take last min from a square box\n",
    "            last_min = np.min([dtw_matrix[i-1, j], dtw_matrix[i, j-1], dtw_matrix[i-1, j-1]])\n",
    "            dtw_matrix[i, j] = cost + last_min\n",
    "    return dtw_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_1 = aux_tone\n",
    "time_series_2 = bpod_trial\n",
    "dtw(time_series_1, time_series_2, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def dtw_alignment(ts_a, ts_b, d=lambda x, y: abs(x - y)):\n",
    "    \"\"\"Computes the Dynamic Time Warping (DTW) alignment between two time series.\n",
    "\n",
    "    Args:\n",
    "        ts_a: First time series (list or array).\n",
    "        ts_b: Second time series (list or array).\n",
    "        d: Distance function. Defaults to absolute difference.\n",
    "\n",
    "    Returns:\n",
    "        path: The optimal path for the alignment.\n",
    "        DTW: The full DTW matrix.\n",
    "    \"\"\"\n",
    "    # Create cost matrix with infinite values\n",
    "    DTW = np.full((len(ts_a) + 1, len(ts_b) + 1), np.inf)\n",
    "    DTW[0, 0] = 0\n",
    "\n",
    "    # Populate the cost matrix\n",
    "    for i in range(1, len(ts_a) + 1):\n",
    "        for j in range(1, len(ts_b) + 1):\n",
    "            cost = d(ts_a[i-1], ts_b[j-1])\n",
    "            DTW[i, j] = cost + min(DTW[i-1, j],    # insertion\n",
    "                                   DTW[i, j-1],    # deletion\n",
    "                                   DTW[i-1, j-1])  # match\n",
    "\n",
    "    # Backtrack to find the optimal path\n",
    "    path = []\n",
    "    i, j = len(ts_a), len(ts_b)\n",
    "    while i > 0 and j > 0:\n",
    "        path.append((i-1, j-1))\n",
    "        min_index = np.argmin((DTW[i-1, j], DTW[i, j-1], DTW[i-1, j-1]))\n",
    "        if min_index == 0:\n",
    "            i -= 1\n",
    "        elif min_index == 1:\n",
    "            j -= 1\n",
    "        else:  # min_index == 2\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "\n",
    "    # Include the start cell in the path\n",
    "    path.append((0, 0))\n",
    "\n",
    "    path.reverse()\n",
    "    return path, DTW\n",
    "\n",
    "# Example time series data\n",
    "ts_a = aux_tone\n",
    "ts_b = bpod_trial\n",
    "\n",
    "# Get the alignment and DTW matrix\n",
    "alignment_path, DTW_matrix = dtw_alignment(ts_a, ts_b)\n",
    "\n",
    "# The alignment path is returned as tuples of aligned indices\n",
    "alignment_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpod_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_tone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run image processing jobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.Processing.populate(**populate_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.Curation().create1_from_processing_task({'session_id': sessi, 'scan_id': scansi, \"paramset_idx\": selected_s2pparms_index, \"manual_curation\": 0})\n",
    "\n",
    "imaging.MotionCorrection.populate(**populate_settings)\n",
    "\n",
    "imaging.Segmentation.populate(**populate_settings)\n",
    "\n",
    "imaging.MaskClassification.populate(**populate_settings)\n",
    "\n",
    "imaging.Fluorescence.populate(**populate_settings)\n",
    "\n",
    "imaging.Activity.populate(**populate_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_key = (scan.Scan & f'scan_id = \"{scansi}\"').fetch('KEY')[0]\n",
    "curation_key = (imaging.Curation & scan_key & 'curation_id=1').fetch1('KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_overview_movies_rspace(curation_key):\n",
    "    # params_key = (imaging.ProcessingParamSet & 'paramset_idx = \"4\"').fetch('KEY')\n",
    "    # reg_tiffs_available = (imaging.ProcessingParamSet & params_key).fetch(\"params\")[0]['reg_tif']\n",
    "    from scipy.ndimage import mean\n",
    "    import tifffile\n",
    "    path = (scan.ScanPath & curation_key).fetch1(\"path\") + (\"/suite2p/plane0/reg_tif\")\n",
    "\n",
    "    # path = '/datajoint-data/data/jisooj/RN_OPI-1681_2023-02-15_scan9FGLEFJ3_sess9FGLEFJ3/suite2p_exp9FGLEFJ3/suite2p/plane0/reg_tif'\n",
    "    # Get a list of all tiff files in the folder\n",
    "    tiff_files = [os.path.join(path, f) for f in natsorted(os.listdir(path)) if f.endswith('.tif')]\n",
    "\n",
    "    # print(tiff_files)\n",
    "\n",
    "    # Load each tiff stack into a list of numpy arrays\n",
    "    stacks = []\n",
    "    for f in tiff_files:\n",
    "        with tifffile.TiffFile(f) as tif:\n",
    "            # Get the number of pages in the file\n",
    "            num_pages = len(tif.pages)\n",
    "            \n",
    "            # Create a numpy array to store all pages\n",
    "            stack = np.zeros((num_pages,) + tif.pages[0].shape, dtype=tif.pages[0].dtype)\n",
    "            \n",
    "            # Iterate over the pages and store them in the array\n",
    "            for i, page in enumerate(tif.pages):\n",
    "                stack[i] = page.asarray()\n",
    "\n",
    "        stacks.append(stack)\n",
    "\n",
    "    # Concatenate the stacks into a single numpy array along the z-axis\n",
    "    volume = np.concatenate(stacks, axis=0)\n",
    "\n",
    "    # delete registration tiff\n",
    "    for f in tiff_files:\n",
    "        os.remove(f) \n",
    "    \n",
    "    ### moving average filter\n",
    "    # Create a running Z mean projection of the volume\n",
    "\n",
    "    runav = 30\n",
    "    # running_z_projection = uniform_filter_mt(volume, size=(runav,xyrunav,xyrunav))\n",
    "    running_z_projection = sh.rolling_average_filter(volume, runav)\n",
    "\n",
    "    session_id = curation_key['session_id']\n",
    "    scan_id = curation_key['scan_id']\n",
    "\n",
    "    filename = os.path.join(path, 'registered_movie_' + session_id + '_' + scan_id + '_' + str(runav) + '_frame_runningaverage2' + '.mp4')\n",
    "\n",
    "    fps = 120   # frames per second - 120 default\n",
    "    p1 = 2       # percentile scaling low - 1 default\n",
    "    p2 = 99.998  # percentile scaling high - 99.995 default\n",
    "\n",
    "    rescaled_image_8bit = sh.make_stack_movie(running_z_projection, filename, fps, p1, p2)\n",
    "\n",
    "    tmpdir = dj.config['custom'].get('suite2p_fast_tmp')[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_overview_movies_rspace(curation_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pose estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.Diagram(model) + dj.Diagram(equipment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - -\n",
      "DLC pose estimation: scan9FKWT95S\n"
     ]
    }
   ],
   "source": [
    "aux_setup_typestr = (scan.ScanInfo() & 'scan_id = \"' + scansi + '\"').fetch(\"userfunction_info\")[0]\n",
    "selected_DLCmodel = 'Topcam_2bin_with_scope'\n",
    "print('- - - -')\n",
    "print('DLC pose estimation:', scansi)\n",
    "\n",
    "# insert TOP movie into model table\n",
    "scan_key = (scan.Scan & f'scan_id = \"{scansi}\"').fetch('KEY')[0] \n",
    "moviepath = str(list(pathlib.Path((scan.ScanPath() & scan_key).fetch(\"path\")[0]).glob(\"*top*.mp4*\"))[0])\n",
    "\n",
    "key = {'session_id': scan_key[\"session_id\"],\n",
    "    'recording_id': scan_key[\"scan_id\"], \n",
    "    'camera': \"mini2p1_top\", # Currently 'scanner' due to in equipment tables\n",
    "    }\n",
    "model.VideoRecording.insert1(key, skip_duplicates=True)\n",
    "\n",
    "key.update({'file_path': moviepath,\n",
    "            'file_id': 0})  #INCREMENT FILE_ID WITH CAM NUMBER?\n",
    "\n",
    "model.VideoRecording.File.insert1(key, ignore_extra_fields=True, skip_duplicates=True)\n",
    "model.RecordingInfo.populate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    <style type=\"text/css\">\n",
       "        .Table{\n",
       "            border-collapse:collapse;\n",
       "        }\n",
       "        .Table th{\n",
       "            background: #A0A0A0; color: #ffffff; padding:4px; border:#f0e0e0 1px solid;\n",
       "            font-weight: normal; font-family: monospace; font-size: 100%;\n",
       "        }\n",
       "        .Table td{\n",
       "            padding:4px; border:#f0e0e0 1px solid; font-size:100%;\n",
       "        }\n",
       "        .Table tr:nth-child(odd){\n",
       "            background: #ffffff;\n",
       "            color: #000000;\n",
       "        }\n",
       "        .Table tr:nth-child(even){\n",
       "            background: #f3f1ff;\n",
       "            color: #000000;\n",
       "        }\n",
       "        /* Tooltip container */\n",
       "        .djtooltip {\n",
       "        }\n",
       "        /* Tooltip text */\n",
       "        .djtooltip .djtooltiptext {\n",
       "            visibility: hidden;\n",
       "            width: 120px;\n",
       "            background-color: black;\n",
       "            color: #fff;\n",
       "            text-align: center;\n",
       "            padding: 5px 0;\n",
       "            border-radius: 6px;\n",
       "            /* Position the tooltip text - see examples below! */\n",
       "            position: absolute;\n",
       "            z-index: 1;\n",
       "        }\n",
       "        #primary {\n",
       "            font-weight: bold;\n",
       "            color: black;\n",
       "        }\n",
       "        #nonprimary {\n",
       "            font-weight: normal;\n",
       "            color: white;\n",
       "        }\n",
       "\n",
       "        /* Show the tooltip text when you mouse over the tooltip container */\n",
       "        .djtooltip:hover .djtooltiptext {\n",
       "            visibility: visible;\n",
       "        }\n",
       "    </style>\n",
       "    \n",
       "    \n",
       "        <div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "        <table border=\"1\" class=\"Table\">\n",
       "            <thead> <tr style=\"text-align: right;\"> <th> <div class=\"djtooltip\">\n",
       "                            <p id=\"primary\">session_id</p>\n",
       "                            <span class=\"djtooltiptext\"></span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"primary\">recording_id</p>\n",
       "                            <span class=\"djtooltiptext\"></span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"primary\">file_id</p>\n",
       "                            <span class=\"djtooltiptext\"></span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">file_path</p>\n",
       "                            <span class=\"djtooltiptext\">filepath of video, relative to root data directory</span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">camera</p>\n",
       "                            <span class=\"djtooltiptext\"></span>\n",
       "                        </div> </th> </tr> </thead>\n",
       "            <tbody> <tr> <td>sess9FKWT95S</td>\n",
       "<td>scan9FKWT95S</td>\n",
       "<td>0</td>\n",
       "<td>/datajoint-data/data/tobiasr/JJ_ROS-1627_2023-11-03_scan9FKWT95S_sess9FKWT95S/scan9FKWT95S_mini2p1_top_video_2023-11-03T15_22_52.mp4</td>\n",
       "<td>mini2p1_top</td> </tr> </tbody>\n",
       "        </table>\n",
       "        \n",
       "        <p>Total: 1</p></div>\n",
       "        "
      ],
      "text/plain": [
       "*session_id    *recording_id  *file_id    file_path      camera        \n",
       "+------------+ +------------+ +---------+ +------------+ +------------+\n",
       "sess9FKWT95S   scan9FKWT95S   0           /datajoint-dat mini2p1_top   \n",
       " (Total: 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.VideoRecording.File * model.VideoRecording() &  'recording_id = \"' + scansi + '\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'session_id': 'sess9FKWT95S',\n",
       " 'recording_id': 'scan9FKWT95S',\n",
       " 'model_name': 'Topcam_2bin_with_scope',\n",
       " 'task_mode': 'trigger'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key =  (model.VideoRecording & f'recording_id=\"{scansi}\"').fetch1('KEY')\n",
    "key.update({'model_name': selected_DLCmodel, 'task_mode': 'trigger'}) \n",
    "key      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT pose estimation task\n",
    "model.PoseEstimationTask.insert_estimation_task(key, key[\"model_name\"], analyze_videos_params={'save_as_csv':True, 'dynamic':(True,.5,60)}) # dynamic cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    <style type=\"text/css\">\n",
       "        .Table{\n",
       "            border-collapse:collapse;\n",
       "        }\n",
       "        .Table th{\n",
       "            background: #A0A0A0; color: #ffffff; padding:4px; border:#f0e0e0 1px solid;\n",
       "            font-weight: normal; font-family: monospace; font-size: 100%;\n",
       "        }\n",
       "        .Table td{\n",
       "            padding:4px; border:#f0e0e0 1px solid; font-size:100%;\n",
       "        }\n",
       "        .Table tr:nth-child(odd){\n",
       "            background: #ffffff;\n",
       "            color: #000000;\n",
       "        }\n",
       "        .Table tr:nth-child(even){\n",
       "            background: #f3f1ff;\n",
       "            color: #000000;\n",
       "        }\n",
       "        /* Tooltip container */\n",
       "        .djtooltip {\n",
       "        }\n",
       "        /* Tooltip text */\n",
       "        .djtooltip .djtooltiptext {\n",
       "            visibility: hidden;\n",
       "            width: 120px;\n",
       "            background-color: black;\n",
       "            color: #fff;\n",
       "            text-align: center;\n",
       "            padding: 5px 0;\n",
       "            border-radius: 6px;\n",
       "            /* Position the tooltip text - see examples below! */\n",
       "            position: absolute;\n",
       "            z-index: 1;\n",
       "        }\n",
       "        #primary {\n",
       "            font-weight: bold;\n",
       "            color: black;\n",
       "        }\n",
       "        #nonprimary {\n",
       "            font-weight: normal;\n",
       "            color: white;\n",
       "        }\n",
       "\n",
       "        /* Show the tooltip text when you mouse over the tooltip container */\n",
       "        .djtooltip:hover .djtooltiptext {\n",
       "            visibility: visible;\n",
       "        }\n",
       "    </style>\n",
       "    \n",
       "    \n",
       "        <div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "        <table border=\"1\" class=\"Table\">\n",
       "            <thead> <tr style=\"text-align: right;\"> <th> <div class=\"djtooltip\">\n",
       "                            <p id=\"primary\">session_id</p>\n",
       "                            <span class=\"djtooltiptext\"></span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"primary\">recording_id</p>\n",
       "                            <span class=\"djtooltiptext\"></span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"primary\">model_name</p>\n",
       "                            <span class=\"djtooltiptext\">User-friendly model name</span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"primary\">file_id</p>\n",
       "                            <span class=\"djtooltiptext\"></span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">task_mode</p>\n",
       "                            <span class=\"djtooltiptext\">load results or trigger computation</span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">pose_estimation_output_dir</p>\n",
       "                            <span class=\"djtooltiptext\">output dir relative to the root dir</span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">pose_estimation_params</p>\n",
       "                            <span class=\"djtooltiptext\">analyze_videos params, if not default</span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">camera</p>\n",
       "                            <span class=\"djtooltiptext\"></span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">file_path</p>\n",
       "                            <span class=\"djtooltiptext\">filepath of video, relative to root data directory</span>\n",
       "                        </div> </th> </tr> </thead>\n",
       "            <tbody> <tr> <td>sess9FKWT95S</td>\n",
       "<td>scan9FKWT95S</td>\n",
       "<td>Topcam_2bin_with_scope</td>\n",
       "<td>0</td>\n",
       "<td>trigger</td>\n",
       "<td>/datajoint-data/data/tobiasr/JJ_ROS-1627_2023-11-03_scan9FKWT95S_sess9FKWT95S/device_mini2p1_top_recording_scan9FKWT95S_model_Topcam_2bin_with_scope</td>\n",
       "<td>=BLOB=</td>\n",
       "<td>mini2p1_top</td>\n",
       "<td>/datajoint-data/data/tobiasr/JJ_ROS-1627_2023-11-03_scan9FKWT95S_sess9FKWT95S/scan9FKWT95S_mini2p1_top_video_2023-11-03T15_22_52.mp4</td> </tr> </tbody>\n",
       "        </table>\n",
       "        \n",
       "        <p>Total: 1</p></div>\n",
       "        "
      ],
      "text/plain": [
       "*session_id    *recording_id  *model_name    *file_id    task_mode     pose_estimatio pose_estim camera         file_path     \n",
       "+------------+ +------------+ +------------+ +---------+ +-----------+ +------------+ +--------+ +------------+ +------------+\n",
       "sess9FKWT95S   scan9FKWT95S   Topcam_2bin_wi 0           trigger       /datajoint-dat =BLOB=     mini2p1_top    /datajoint-dat\n",
       " (Total: 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.PoseEstimationTask() * model.VideoRecording * model.VideoRecording.File()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    <style type=\"text/css\">\n",
       "        .Table{\n",
       "            border-collapse:collapse;\n",
       "        }\n",
       "        .Table th{\n",
       "            background: #A0A0A0; color: #ffffff; padding:4px; border:#f0e0e0 1px solid;\n",
       "            font-weight: normal; font-family: monospace; font-size: 100%;\n",
       "        }\n",
       "        .Table td{\n",
       "            padding:4px; border:#f0e0e0 1px solid; font-size:100%;\n",
       "        }\n",
       "        .Table tr:nth-child(odd){\n",
       "            background: #ffffff;\n",
       "            color: #000000;\n",
       "        }\n",
       "        .Table tr:nth-child(even){\n",
       "            background: #f3f1ff;\n",
       "            color: #000000;\n",
       "        }\n",
       "        /* Tooltip container */\n",
       "        .djtooltip {\n",
       "        }\n",
       "        /* Tooltip text */\n",
       "        .djtooltip .djtooltiptext {\n",
       "            visibility: hidden;\n",
       "            width: 120px;\n",
       "            background-color: black;\n",
       "            color: #fff;\n",
       "            text-align: center;\n",
       "            padding: 5px 0;\n",
       "            border-radius: 6px;\n",
       "            /* Position the tooltip text - see examples below! */\n",
       "            position: absolute;\n",
       "            z-index: 1;\n",
       "        }\n",
       "        #primary {\n",
       "            font-weight: bold;\n",
       "            color: black;\n",
       "        }\n",
       "        #nonprimary {\n",
       "            font-weight: normal;\n",
       "            color: white;\n",
       "        }\n",
       "\n",
       "        /* Show the tooltip text when you mouse over the tooltip container */\n",
       "        .djtooltip:hover .djtooltiptext {\n",
       "            visibility: visible;\n",
       "        }\n",
       "    </style>\n",
       "    \n",
       "    <b></b>\n",
       "        <div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "        <table border=\"1\" class=\"Table\">\n",
       "            <thead> <tr style=\"text-align: right;\"> <th> <div class=\"djtooltip\">\n",
       "                            <p id=\"primary\">session_id</p>\n",
       "                            <span class=\"djtooltiptext\"></span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"primary\">recording_id</p>\n",
       "                            <span class=\"djtooltiptext\"></span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">px_height</p>\n",
       "                            <span class=\"djtooltiptext\">height in pixels</span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">px_width</p>\n",
       "                            <span class=\"djtooltiptext\">width in pixels</span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">nframes</p>\n",
       "                            <span class=\"djtooltiptext\">number of frames</span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">fps</p>\n",
       "                            <span class=\"djtooltiptext\">(Hz) frames per second</span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">recording_datetime</p>\n",
       "                            <span class=\"djtooltiptext\">Datetime for the start of the recording</span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">recording_duration</p>\n",
       "                            <span class=\"djtooltiptext\">video duration (s) from nframes / fps</span>\n",
       "                        </div> </th> </tr> </thead>\n",
       "            <tbody> <tr> <td>sess9FKW82R3</td>\n",
       "<td>scan9FKW82R3</td>\n",
       "<td>500</td>\n",
       "<td>500</td>\n",
       "<td>36031</td>\n",
       "<td>60</td>\n",
       "<td>None</td>\n",
       "<td>600.517</td></tr><tr><td>sess9FKWT95S</td>\n",
       "<td>scan9FKWT95S</td>\n",
       "<td>500</td>\n",
       "<td>500</td>\n",
       "<td>36056</td>\n",
       "<td>60</td>\n",
       "<td>None</td>\n",
       "<td>600.933</td></tr><tr><td>sess9FKWTLNS</td>\n",
       "<td>scan9FKWTLNS</td>\n",
       "<td>500</td>\n",
       "<td>500</td>\n",
       "<td>36600</td>\n",
       "<td>60</td>\n",
       "<td>None</td>\n",
       "<td>610.0</td> </tr> </tbody>\n",
       "        </table>\n",
       "        \n",
       "        <p>Total: 3</p></div>\n",
       "        "
      ],
      "text/plain": [
       "*session_id    *recording_id  px_height     px_width     nframes     fps     recording_date recording_dura\n",
       "+------------+ +------------+ +-----------+ +----------+ +---------+ +-----+ +------------+ +------------+\n",
       "sess9FKW82R3   scan9FKW82R3   500           500          36031       60      None           600.517       \n",
       "sess9FKWT95S   scan9FKWT95S   500           500          36056       60      None           600.933       \n",
       "sess9FKWTLNS   scan9FKWTLNS   500           500          36600       60      None           610.0         \n",
       " (Total: 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.RecordingInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-15 09:29:27.504058: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-15 09:29:27.629366: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/tobiasr/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-11-15 09:29:27.629388: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-11-15 09:29:27.659084: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-15 09:29:28.213281: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/tobiasr/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-11-15 09:29:28.213339: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/tobiasr/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-11-15 09:29:28.213345: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 2.3.4...\n",
      "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n",
      "Using snapshot-120000 for model /datajoint-data/models/tobiasr/NK_DLC_tracking/Topcam_2bin_withscope-NK-2023-08-31/dlc-models/iteration-0/Topcam_2bin_withscopeAug31-trainset95shuffle1\n",
      "Starting analysis in dynamic cropping mode with parameters: (True, 0.5, 60)\n",
      "Switching batchsize to 1, num_outputs (per animal) to 1 and TFGPUinference to False (all these features are not supported in this mode).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tobiasr/miniconda3/envs/datajoint-DLCbackup/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "2023-11-15 09:29:32.495288: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/tobiasr/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-11-15 09:29:32.495312: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-11-15 09:29:32.495332: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tatchu3): /proc/driver/nvidia/version does not exist\n",
      "2023-11-15 09:29:32.495584: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-15 09:29:32.525799: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /datajoint-data/data/tobiasr/JJ_ROS-1627_2023-11-03_scan9FKWT95S_sess9FKWT95S/scan9FKWT95S_mini2p1_top_video_2023-11-03T15_22_52.mp4\n",
      "Loading  /datajoint-data/data/tobiasr/JJ_ROS-1627_2023-11-03_scan9FKWT95S_sess9FKWT95S/scan9FKWT95S_mini2p1_top_video_2023-11-03T15_22_52.mp4\n",
      "Duration of video [s]:  600.93 , recorded with  60.0 fps!\n",
      "Overall # of frames:  36056  found with (before cropping) frame dimensions:  500 500\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 36000/36056 [13:11<00:01, 45.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /datajoint-data/data/tobiasr/JJ_ROS-1627_2023-11-03_scan9FKWT95S_sess9FKWT95S/device_mini2p1_top_recording_scan9FKWT95S_model_Topcam_2bin_with_scope...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n"
     ]
    }
   ],
   "source": [
    "# run pose estimation\n",
    "model.PoseEstimation.populate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make labeled video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process video: /datajoint-data/data/tobiasr/JJ_ROS-1627_2023-11-03_scan9FKWT95S_sess9FKWT95S/scan9FKWT95S_mini2p1_top_video_2023-11-03T15_22_52.mp4\n",
      "Loading /datajoint-data/data/tobiasr/JJ_ROS-1627_2023-11-03_scan9FKWT95S_sess9FKWT95S/scan9FKWT95S_mini2p1_top_video_2023-11-03T15_22_52.mp4 and data.\n",
      "Duration of video [s]: 600.93, recorded with 60.0 fps!\n",
      "Overall # of frames: 36056 with cropped frame dimensions: 500 500\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36056/36056 [01:27<00:00, 410.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deeplabcut.utils.make_labeled_video import create_labeled_video\n",
    "import yaml\n",
    "from element_interface.utils import find_full_path\n",
    "from adamacs.paths import get_dlc_root_data_dir\n",
    "\n",
    "\n",
    "destfolder = model.PoseEstimationTask.infer_output_dir(key)\n",
    "destfolder\n",
    "\n",
    "video_path = find_full_path( # Fetch the full video path\n",
    "    get_dlc_root_data_dir(), ((model.VideoRecording.File & key).fetch1(\"file_path\"))\n",
    ")\n",
    "\n",
    "config_paths = sorted( # Of configs in the project path, defer to the datajoint-saved\n",
    "    list(\n",
    "        find_full_path(\n",
    "            get_dlc_root_data_dir(), ((model.Model & key).fetch1(\"project_path\"))\n",
    "        ).glob(\"*.y*ml\")\n",
    "    )\n",
    ")\n",
    "\n",
    "create_labeled_video( # Pass strings to label the video\n",
    "    config=str(config_paths[-1]),\n",
    "    videos=str(video_path),\n",
    "    destfolder=str(destfolder),\n",
    ")\n",
    "\n",
    "# list(list(pathlib.Path((model.VideoRecording.File & key).fetch1(\"file_path\")).parent.glob(\"device*\"))[0].glob(\"*.y*ml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "mp4_files = glob.glob(f\"{destfolder}/*.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/datajoint-data/data/tobiasr/JJ_ROS-1627_2023-11-03_scan9FKWT95S_sess9FKWT95S/device_mini2p1_top_recording_scan9FKWT95S_model_Topcam_2bin_with_scope/scan9FKWT95S_mini2p1_top_video_2023-11-03T15_22_52DLC_resnet50_Topcam_2bin_withscopeAug31shuffle1_120000_labeled.mp4']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp4_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pose_estimation_time</th>\n",
       "      <th>subject</th>\n",
       "      <th>session_datetime</th>\n",
       "      <th>name</th>\n",
       "      <th>shorthand</th>\n",
       "      <th>initials</th>\n",
       "      <th>email</th>\n",
       "      <th>lab</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th>recording_id</th>\n",
       "      <th>model_name</th>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sess9FKWT95S</th>\n",
       "      <th>scan9FKWT95S</th>\n",
       "      <th>Topcam_2bin_with_scope</th>\n",
       "      <th>6</th>\n",
       "      <td>2023-11-15 09:42:45</td>\n",
       "      <td>ROS-1627</td>\n",
       "      <td>2023-11-03</td>\n",
       "      <td>Jung Jisoo</td>\n",
       "      <td>jisooj</td>\n",
       "      <td>JJ</td>\n",
       "      <td>jjun1@uni-bonn.de</td>\n",
       "      <td>Rose</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         pose_estimation_time   \n",
       "session_id   recording_id model_name             user_id                        \n",
       "sess9FKWT95S scan9FKWT95S Topcam_2bin_with_scope 6        2023-11-15 09:42:45  \\\n",
       "\n",
       "                                                           subject   \n",
       "session_id   recording_id model_name             user_id             \n",
       "sess9FKWT95S scan9FKWT95S Topcam_2bin_with_scope 6        ROS-1627  \\\n",
       "\n",
       "                                                         session_datetime   \n",
       "session_id   recording_id model_name             user_id                    \n",
       "sess9FKWT95S scan9FKWT95S Topcam_2bin_with_scope 6             2023-11-03  \\\n",
       "\n",
       "                                                                name   \n",
       "session_id   recording_id model_name             user_id               \n",
       "sess9FKWT95S scan9FKWT95S Topcam_2bin_with_scope 6        Jung Jisoo  \\\n",
       "\n",
       "                                                         shorthand initials   \n",
       "session_id   recording_id model_name             user_id                      \n",
       "sess9FKWT95S scan9FKWT95S Topcam_2bin_with_scope 6          jisooj       JJ  \\\n",
       "\n",
       "                                                                      email   \n",
       "session_id   recording_id model_name             user_id                      \n",
       "sess9FKWT95S scan9FKWT95S Topcam_2bin_with_scope 6        jjun1@uni-bonn.de  \\\n",
       "\n",
       "                                                           lab  \n",
       "session_id   recording_id model_name             user_id        \n",
       "sess9FKWT95S scan9FKWT95S Topcam_2bin_with_scope 6        Rose  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.PoseEstimation() * session.Session * session.SessionUser * subject.User()).fetch(format = \"frame\", order_by = \"session_datetime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/datajoint-data/data/tobiasr/JJ_ROS-1627_2023-11-03_scan9FKWT95S_sess9FKWT95S/scan9FKWT95S_mini2p1_top_video_2023-11-03T15_22_52.mp4'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scansi = \"scan9FKWT95S\"\n",
    "scan_key = (model.PoseEstimation & f'recording_id = \"{scansi}\"').fetch('KEY')[0] \n",
    "path = (model.VideoRecording.File & scan_key).fetch(\"file_path\")\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([array([248.18189764, 249.82993031, 249.69035816, ..., 478.01813698,\n",
       "               477.77332449, 477.69083166])                                ],\n",
       "       dtype=object),\n",
       " array([array([ 32.17335296,  28.48447275,  31.41013908, ..., 227.96029496,\n",
       "               227.80529046, 225.29934216])                                ],\n",
       "       dtype=object)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.PoseEstimation.BodyPartPosition() & scan_key & 'body_part = \"head_middle\"').fetch(\"x_pos\", \"y_pos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning. Use with caution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.ProcessingTask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject.Subject.delete()\n",
    "# session.Session.delete()\n",
    "# imaging.Processing.delete()\n",
    "# imaging.Curation.delete()\n",
    "# event.Event.delete()\n",
    "# event.BehaviorRecording.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-11-15 09:28:59,495][INFO]: Deleting 14 rows from `tobiasr02_model`.`__pose_estimation__body_part_position`\n",
      "[2023-11-15 09:28:59,498][INFO]: Deleting 2 rows from `tobiasr02_model`.`__pose_estimation`\n",
      "[2023-11-15 09:28:59,500][INFO]: Deleting 3 rows from `tobiasr02_model`.`pose_estimation_task`\n",
      "[2023-11-15 09:29:05,680][INFO]: Deletes committed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = (session.Session & \"session_datetime >= '2023-10-01'\").fetch('KEY')\n",
    "# (session.Session & \"session_datetime >= '2023-10-01'\").delete()\n",
    "# (imaging.ProcessingTask & \"session_id LIKE 'sess9FKWT2RT%'\").delete()\n",
    "# (imaging.ProcessingTask  & key).delete()\n",
    "(model.PoseEstimationTask & key).delete()\n",
    "# (session.Session & \"session_id LIKE 'sess9FKWT2RT%'\").delete()\n",
    "# (subject.Subject & \"subject = 'ROS-1571'\").delete()\n",
    "# # subject.Subject.delete()\n",
    "# # session.Session.delete()\n",
    "# # imaging.Processing.delete()\n",
    "# # imaging.Curation.delete()\n",
    "# # event.Event.delete()\n",
    "# # event.BehaviorRecording.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.Session.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session.Session.drop()\n",
    "# scan.Scan.drop()\n",
    "# imaging.Processing.drop()\n",
    "# imaging.Curation.drop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datajoint-DLCbackup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

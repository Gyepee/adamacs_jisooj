{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-05-12 21:44:55,745][INFO]: Connecting tobiasr@172.26.128.53:3306\n",
      "[2023-05-12 21:44:55,793][INFO]: Connected tobiasr@172.26.128.53:3306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.14.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# change to the upper level folder to detect dj_local_conf.json\n",
    "if os.path.basename(os.getcwd())=='notebooks': os.chdir('..')\n",
    "assert os.path.basename(os.getcwd())=='adamacs', (\"Please move to the main directory\")\n",
    "from adamacs.pipeline import subject, session, equipment, surgery, event, trial, imaging, scan, model\n",
    "from adamacs.ingest import session as isess\n",
    "from adamacs.helpers import stack_helpers as sh\n",
    "from adamacs.ingest import behavior as ibe\n",
    "import datajoint as dj\n",
    "from rspace_client.eln import eln\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "dj.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get latest dataset from Natasha from database\n",
    "2. load 2p movie to array. \n",
    "3. load top-video to array\n",
    "4. find the Start and end frames of the movie with respect to the tracking gate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "import cv2\n",
    "\n",
    "def get_closest_timestamps(series, target_timestamp):\n",
    "    # List to store the indices\n",
    "    indices = []\n",
    "\n",
    "    # For each timestamp in series1, find the closest timestamp in series2 and get its index\n",
    "    for t1 in series:\n",
    "        closest_index = closest_timestamp(target_timestamp, t1)\n",
    "        indices.append(closest_index)\n",
    "    return indices\n",
    "\n",
    "# Function to find closest timestamp\n",
    "def closest_timestamp(series, target_timestamp):\n",
    "    index = bisect.bisect_left(series, target_timestamp)\n",
    "    if index == 0:\n",
    "        return 0\n",
    "    if index == len(series):\n",
    "        return len(series)-1\n",
    "    before = series[index - 1]\n",
    "    after = series[index]\n",
    "    if after - target_timestamp < target_timestamp - before:\n",
    "       return index\n",
    "    else:\n",
    "       return index-1\n",
    "\n",
    "\n",
    "def selected_frames(video, frame_indices):\n",
    "    \"\"\"\n",
    "    Resize selected frames of a video.\n",
    "\n",
    "    Parameters:\n",
    "    video (np.array): Input video as a numpy array of shape (frames, height, width, channels).\n",
    "    frame_indices (np.array): Indices of the frames to resize and keep.\n",
    "    new_size (tuple): The target height and width as a tuple (height, width).\n",
    "\n",
    "    Returns:\n",
    "    np.array: A numpy array of the resized video.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a boolean mask of the same size as the number of frames\n",
    "    mask = np.zeros(video.shape[0], dtype=bool)\n",
    "\n",
    "    # Set the indices you're interested in to True\n",
    "    mask[frame_indices] = True\n",
    "\n",
    "    # Apply the mask to the video to get the frames you're interested in\n",
    "    selected_frames = video[mask]\n",
    "\n",
    "\n",
    "\n",
    "    return selected_frames\n",
    "\n",
    "\n",
    "\n",
    "def resize_movie(movie, new_height, new_width):\n",
    "    # Get the number of frames and color channels\n",
    "    num_frames, _, _, num_channels = movie.shape\n",
    "    \n",
    "    # Initialize an empty array for the scaled movie\n",
    "    scaled_movie = np.empty((num_frames, new_height, new_width, num_channels))\n",
    "    \n",
    "    # Iterate through each frame\n",
    "    for i in tqdm(range(num_frames), desc=\"Resizing frames\"):\n",
    "        # Resize the frame and store it in the new array\n",
    "        scaled_movie[i] = cv2.resize(movie[i], (new_width, new_height), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    # Return the scaled movie\n",
    "    return scaled_movie\n",
    "\n",
    "\n",
    "def resize_frame(frame, new_height, new_width):\n",
    "    return cv2.resize(frame, (new_width, new_height), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "def resize_movie_mt(movie, new_height, new_width):\n",
    "    num_frames, _, _, num_channels = movie.shape\n",
    "    scaled_movie = np.empty((num_frames, new_height, new_width, num_channels))\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        for i, resized_frame in tqdm(enumerate(executor.map(resize_frame, movie, [new_height]*num_frames, [new_width]*num_frames)), total=num_frames, desc=\"Resizing frames\"):\n",
    "            scaled_movie[i] = resized_frame\n",
    "\n",
    "    return scaled_movie\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "import concurrent.futures\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining queries\n",
    "\n",
    "user = \"NK\"\n",
    "userquery = (session.SessionUser * subject.User() & f'initials = \"{user}\"')\n",
    "# get the latest session\n",
    "usesession = session.Session.fetch(order_by='session_datetime DESC', as_dict=True)[0][\"session_id\"]\n",
    "sessionquery = session.Session &  f'session_id = \"{usesession}\"'\n",
    "\n",
    "scansi = (scan.Scan & sessionquery).fetch('scan_id')[0]\n",
    "scanquery = scan.Scan & f'scan_id = \"{scansi}\"'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import skvideo.io\n",
    "\n",
    "# get the main data directory of the latest session of the specified user\n",
    "# dir = (session.SessionDirectory & sessionquery).fetch('session_dir')\n",
    "dir = (scan.ScanPath & scanquery).fetch('path')\n",
    "directory = Path(dir[0])\n",
    "pattern = '*top_video*.mp4'\n",
    "files = list(directory.glob(pattern))\n",
    "videodata = np.asarray(skvideo.io.vread(str(files[0])), dtype=np.uint8)\n",
    "# videodata = np.asarray(videodata, dtype=np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the blinking movie data of the latest session of the specified user\n",
    "directory = Path(dir[0] + \"/suite2p/plane0/reg_tif\")\n",
    "pattern = '*80_frame*.mp4'\n",
    "files = list(directory.glob(pattern))\n",
    "blinkvideodata = np.asarray(skvideo.io.vread(str(files[0])), dtype=np.uint8)\n",
    "# blinkvideodata = np.asarray(blinkvideodata, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36157, 1000, 1000, 3)\n",
      "(9230, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "print(videodata.shape)\n",
    "print(blinkvideodata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ed1167e42d3417cb0398d59c1c1dc46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='z', max=36156), Output()), _dom_classes=('widget-interac…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sh.display_volume_z(videodata,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3986729670144f285fc1966df5cfd46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='z', max=9229), Output()), _dom_classes=('widget-interact…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sh.display_volume_z(blinkvideodata,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxgatetimestamp_end = (event.Event()  &  \"event_type='main_track_gate'\" &  scanquery ).fetch('event_end_time')\n",
    "auxgatetimestamp_start = (event.Event()  &  \"event_type='main_track_gate'\" &  scanquery ).fetch('event_start_time')\n",
    "cameratimestamps = (event.Event()  &  \"event_type='aux_cam'\" & f\"event_start_time>{auxgatetimestamp_start[0]}\" & f\"event_start_time<{auxgatetimestamp_end[0]}\" & scanquery).fetch('event_start_time')\n",
    "twoptimestamps = (event.Event()  &  \"event_type='mini2p_frames'\" &  scanquery ).fetch('event_start_time')\n",
    "cameratimestamps = cameratimestamps - twoptimestamps[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_cameraframes = get_closest_timestamps(twoptimestamps,cameratimestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9230,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(aligned_cameraframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(aligned_cameraframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(k|{0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36037,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(cameratimestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resliced_video = selected_frames(videodata, aligned_cameraframes)\n",
    "resliced_video = np.asarray(resliced_video, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "np.unique(resliced_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh.display_volume_z(resliced_video,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resizing frames: 100%|██████████| 9230/9230 [02:12<00:00, 69.72it/s] \n"
     ]
    }
   ],
   "source": [
    "# rescaled_movie = resize_movie_mt(blinkvideodata, np.shape(videodata)[1], np.shape(videodata)[2])\n",
    "rescaled_movie = resize_movie_mt(blinkvideodata, 1000,1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f12a7b49a216460588be552981b2ebbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='z', max=9229), Output()), _dom_classes=('widget-interact…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sh.display_volume_z(rescaled_movie,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9230, 1000, 1000, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(rescaled_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_rate_video1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps_video1[0] - timestamps_video2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.VideoRecording()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

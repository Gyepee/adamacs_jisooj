{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-07-19 10:44:29,177][INFO]: Connecting tobiasr@172.26.128.53:3306\n",
      "[2023-07-19 10:44:29,225][INFO]: Connected tobiasr@172.26.128.53:3306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.14.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# change to the upper level folder to detect dj_local_conf.json\n",
    "if os.path.basename(os.getcwd())=='notebooks': os.chdir('..')\n",
    "assert os.path.basename(os.getcwd())=='adamacs', (\"Please move to the main directory\")\n",
    "from adamacs.pipeline import subject, session, equipment, surgery, event, trial, imaging, scan, model\n",
    "from adamacs.ingest import session as isess\n",
    "from adamacs.helpers import stack_helpers as sh\n",
    "from adamacs.ingest import behavior as ibe\n",
    "import datajoint as dj\n",
    "from rspace_client.eln import eln\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "dj.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get latest dataset from Natasha from database\n",
    "2. load 2p movie to array. \n",
    "3. load top-video to array\n",
    "4. find the Start and end frames of the movie with respect to the tracking gate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "import cv2\n",
    "\n",
    "def get_closest_timestamps(series, target_timestamp):\n",
    "    # List to store the indices\n",
    "    indices = []\n",
    "\n",
    "    # For each timestamp in series1, find the closest timestamp in series2 and get its index\n",
    "    for t1 in series:\n",
    "        closest_index = closest_timestamp(target_timestamp, t1)\n",
    "        indices.append(closest_index)\n",
    "    return indices\n",
    "\n",
    "# Function to find closest timestamp\n",
    "def closest_timestamp(series, target_timestamp):\n",
    "    index = bisect.bisect_left(series, target_timestamp)\n",
    "    if index == 0:\n",
    "        return 0\n",
    "    if index == len(series):\n",
    "        return len(series)-1\n",
    "    before = series[index - 1]\n",
    "    after = series[index]\n",
    "    if after - target_timestamp < target_timestamp - before:\n",
    "       return index\n",
    "    else:\n",
    "       return index-1\n",
    "\n",
    "\n",
    "def resize_movie(movie, new_height, new_width):\n",
    "    # Get the number of frames and color channels\n",
    "    num_frames, _, _, num_channels = movie.shape\n",
    "    \n",
    "    # Initialize an empty array for the scaled movie\n",
    "    scaled_movie = np.empty((num_frames, new_height, new_width, num_channels), dtype=np.uint8)\n",
    "    \n",
    "    # Iterate through each frame\n",
    "    for i in tqdm(range(num_frames), desc=\"Resizing frames\"):\n",
    "        # Resize the frame and store it in the new array\n",
    "        scaled_movie[i] =  cv2.resize(movie[i], (new_width, new_height), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    # Return the scaled movie\n",
    "    return scaled_movie\n",
    "\n",
    "\n",
    "def resize_frame(frame, new_height, new_width):\n",
    "    return cv2.resize(frame, (new_width, new_height), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "def resize_movie_mt(movie, new_height, new_width):\n",
    "    num_frames, _, _, num_channels = movie.shape\n",
    "    scaled_movie = np.empty((num_frames, new_height, new_width, num_channels), dtype=np.uint8)\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        for i, resized_frame in tqdm(enumerate(executor.map(resize_frame, movie, [new_height]*num_frames, [new_width]*num_frames)), total=num_frames, desc=\"Resizing frames\"):\n",
    "            scaled_movie[i] = resized_frame\n",
    "\n",
    "    return scaled_movie\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "import concurrent.futures\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining queries - example for latest recording sessino of specific user\n",
    "\n",
    "# select user\n",
    "user = \"NK\"\n",
    "userquery = (session.SessionUser * subject.User() & f'initials = \"{user}\"')\n",
    "\n",
    "\n",
    "# get the latest session\n",
    "usesession = session.Session.fetch(order_by='session_datetime DESC', as_dict=True)[0][\"session_id\"]\n",
    "sessionquery = session.Session &  f'session_id = \"{usesession}\"'\n",
    "\n",
    "scansi = (scan.Scan & sessionquery).fetch('scan_id')[0]\n",
    "\n",
    "scanquery = scan.Scan & f'scan_id = \"{scansi}\"'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scan_key' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/tobiasr/adamacs/notebooks/14_synchronization_examples_movie_IMU.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B172.26.128.53/home/tobiasr/adamacs/notebooks/14_synchronization_examples_movie_IMU.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m scansi \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mscan9FI3KWP3\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B172.26.128.53/home/tobiasr/adamacs/notebooks/14_synchronization_examples_movie_IMU.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m scanquery \u001b[39m=\u001b[39m scan\u001b[39m.\u001b[39mScan \u001b[39m&\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mscan_id = \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mscansi\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B172.26.128.53/home/tobiasr/adamacs/notebooks/14_synchronization_examples_movie_IMU.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m (event\u001b[39m.\u001b[39mEvent \u001b[39m&\u001b[39m scan_key \u001b[39m&\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mevent_type: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mevent_names[\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scan_key' is not defined"
     ]
    }
   ],
   "source": [
    "# defining queries - example for directly giving scan number\n",
    "\n",
    "\n",
    "scansi = \"scan9FI3KWP3\"\n",
    "\n",
    "scanquery = scan.Scan & f'scan_id = \"{scansi}\"'\n",
    "(event.Event & scan_key & f'event_type: \"{event_names[1]}\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan.ScanInfo & scanquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluos = np.vstack((scanquery * imaging.Fluorescence.Trace).fetch(\"fluorescence\"))\n",
    "plt.figure(figsize=(16,12))\n",
    "plt.imshow(fluos, aspect='auto', cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rastermap import Rastermap\n",
    "from scipy import stats \n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "ops = {'n_components': 1, 'n_X': 100, 'alpha': 1., 'K': 1.,\n",
    "            'nPC': 200, 'constraints': 2, 'annealing': True, 'init': 'pca',\n",
    "            'start_time': 0, 'end_time': -1}\n",
    "\n",
    "S = np.vstack(fluos)# deconvolved\n",
    "# S = nXp.vstack(fluorescence_traces)\n",
    "# we run rastermap the same way that the other scikit-learn embedding algorithms work\n",
    "# model = Rastermap(n_components=1, n_X=100, verbose = True).fit(S) \n",
    "model = Rastermap(n_components=ops['n_components'], n_X=ops['n_X'], nPC=ops['nPC'],\n",
    "                          init=ops['init'], alpha=ops['alpha'], K=ops['K'], constraints=ops['constraints'],\n",
    "                          annealing=ops['annealing'])\n",
    "model.fit(S)\n",
    "# def running_average(X, nbin = 10):\n",
    "#     Y = np.cumsum(X, axis=0)\n",
    "#     Y = Y[nbin:, :] - Y[:-nbin, :]\n",
    "#     return Y\n",
    "# the manifold embedding is in model.embedding\n",
    "isort = np.argsort(model.embedding[:,0])\n",
    "\n",
    "# sort by embedding and smooth over neurons\n",
    "# Sfilt = running_average(S[isort], 0)\n",
    "Sfilt = gaussian_filter1d(S[isort], np.minimum(8,np.maximum(1,int(S.shape[0]*0.001))),axis=0)\n",
    "# Sfilt = np.vstack(fluorescence_traces)\n",
    "Sfilt = stats.zscore(Sfilt, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,12))\n",
    "plt.imshow(Sfilt, vmin = -0.1, vmax=4, aspect='auto', cmap='gray_r')\n",
    "plt.xlabel('time points')\n",
    "plt.ylabel('sorted neurons')\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MOVIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import skvideo.io\n",
    "\n",
    "# get the main data directory of the specified scanID \n",
    "\n",
    "dir = (scan.ScanPath & scanquery).fetch('path')\n",
    "\n",
    "# get the top cam movie of that session\n",
    "directory = Path(dir[0])\n",
    "pattern = '*top_video*.mp4'\n",
    "files = list(directory.glob(pattern))\n",
    "\n",
    "#load to array\n",
    "videodata = skvideo.io.vread(str(files[0]))\n",
    "videodata = np.asarray([skvideo.io.vshape(frame)[0] for frame in videodata], dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the registered moving average (blinking) movie data of the specified scanID\n",
    "directory = Path(dir[0] + \"/suite2p/plane0/reg_tif\")\n",
    "pattern = '*20_frame*.mp4'\n",
    "files = list(directory.glob(pattern))\n",
    "blinkvideodata = skvideo.io.vread(str(files[0]))\n",
    "blinkvideodata = np.asarray([skvideo.io.vshape(frame)[0] for frame in blinkvideodata], dtype=np.uint8)\n",
    "\n",
    "#dimensionts of the original movie (frames, x,y,rgb)\n",
    "print(videodata.shape)\n",
    "print(blinkvideodata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display camaravideo with slider\n",
    "sh.display_volume_z(videodata,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display 2pstackvideo with slider\n",
    "sh.display_volume_z(blinkvideodata,1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synchronization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the timestamp data and gate / offset cameraframes\n",
    "\n",
    "# from the event table get the main recording gate start / end timestamps.\n",
    "auxgatetimestamp_end = (event.Event()  &  \"event_type='main_track_gate'\" &  scanquery ).fetch('event_end_time')\n",
    "auxgatetimestamp_start = (event.Event()  &  \"event_type='main_track_gate'\" &  scanquery ).fetch('event_start_time')\n",
    "\n",
    "# Then return camera start timestamps within the recording gate only \n",
    "cameratimestamps = (event.Event()  &  \"event_type='aux_cam'\" & f\"event_start_time>{auxgatetimestamp_start[0]}\" & f\"event_start_time<{auxgatetimestamp_end[0]}\" & scanquery).fetch('event_start_time')\n",
    "\n",
    "#  and 2p timestamps (which will always be in the recording gate).\n",
    "twoptimestamps = (event.Event()  &  \"event_type='mini2p_frames'\" &  scanquery ).fetch('event_start_time')\n",
    "\n",
    "twoptimestamps =  twoptimestamps[:np.shape(blinkvideodata)[0]] # truncating 2p timestamps to number of 2p videoframes\n",
    "\n",
    "#  Zero camera timestamps on first 2p timestamp. (not necessary)\n",
    "# cameratimestamps = cameratimestamps - twoptimestamps[0]\n",
    "# twoptimestamps = twoptimestamps - twoptimestamps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event.Event() & scanquery  &  \"event_type='aux_cam'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align the two recordings by finding the indices of the closest camera timestamp that fits the 2p frame timestamps by sorted list insertion (\"bisect\"). Be aware: camera frames can be double.\n",
    "aligned_cameraframes = get_closest_timestamps(twoptimestamps,cameratimestamps)\n",
    "\n",
    "# this should have the same shape as the 2p frames:\n",
    "print(np.shape(aligned_cameraframes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# now use this camara frame indices to reslice the video (which now is aligned to the 2p frames on a frame-by-frame level)\n",
    "resliced_cam_video = videodata[aligned_cameraframes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display synchronized movie\n",
    "sh.display_volume_z(resliced_cam_video,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale camera movie to fit size of 2p movie (can take a lot of time and memory)\n",
    "rescaled_cam_movie = resize_movie(resliced_cam_video, np.shape(blinkvideodata)[1],np.shape(blinkvideodata)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(rescaled_cam_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate and display movies\n",
    "concatmovie = np.concatenate((blinkvideodata,rescaled_cam_movie), axis = 2)\n",
    "sh.display_volume_z(concatmovie,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as new movie (without rescaling)\n",
    "\n",
    "\n",
    "filename = str(directory) + '/aligned_stack_cam_movie.mp4'\n",
    "fps = (scan.ScanInfo & scanquery).fetch('fps')\n",
    "# p1 = 0\n",
    "# p2 = 100\n",
    "# trash = sh.make_stack_movie(concatmovie, filename, fps[0], p1, p2)\n",
    "\n",
    "codecset = 'libx264'\n",
    "import imageio\n",
    "import imageio.plugins.ffmpeg as ffmpeg\n",
    "\n",
    "# Create an imageio VideoWriter object to write the video\n",
    "writer = imageio.get_writer(filename, fps=fps[0], codec=codecset, output_params=['-crf', '19'])\n",
    "\n",
    "# # Calculate the 1st and 99th percentile\n",
    "# p1, p99 = np.percentile(running_z_projection[:500,:,:], (p1set, p2set))\n",
    "\n",
    "# # rescale to 8 bit\n",
    "# rescaled_image_8bit = rescale_image_multithreaded(running_z_projection, p1, p99)\n",
    "\n",
    "for page in concatmovie:\n",
    "    writer.append_data(page)\n",
    "\n",
    "# Close the video writer\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speed up, add timestamps etc - all with fast ffmpeg operations\n",
    "\n",
    "import os\n",
    "\n",
    "spedby = 5\n",
    "setpts_value = 1/spedby # change this to your desired value\n",
    "newfps = fps[0]*spedby\n",
    "\n",
    "input_filename = filename\n",
    "# 2. Add timestamps\n",
    "\n",
    "output_filename = str(directory) + '/' + scansi + '_top_video_concatenated' + 'withtimestamps.mp4'\n",
    "command = f\"\"\"ffmpeg -y -i {input_filename} -vf \"drawtext=fontfile=/Library/Fonts/Arial.ttf:timecode='00\\\\\\\\:00\\\\\\\\:00\\\\\\\\:00':rate={fps[0]}:text='':fontsize=20:fontcolor=white:x=530:y=20:box=1:boxcolor=0x00000000@1\" -f mp4 {output_filename}\"\"\"\n",
    "\n",
    "os.system(command)\n",
    "\n",
    "\n",
    "input_filename = output_filename  # 'sped_up_video.mp4'\n",
    "output_filename = str(directory) + '/' +  scansi + '_top_video_concatenated_spedup_' + str(spedby) + 'fold_withtimestamps.mp4'\n",
    "\n",
    "command = f'ffmpeg -y -i {input_filename} -vf \"setpts={setpts_value}*PTS\" -r {newfps}  {output_filename}'\n",
    "\n",
    "\n",
    "\n",
    "os.system(command)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Synchronization of Flash stimulus with 2p data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event.EventType()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the timestamp data and gate / offset cameraframes\n",
    "\n",
    "# from the event table get the main recording gate start / end timestamps.\n",
    "auxgatetimestamp_end = (event.Event()  &  \"event_type='main_track_gate'\" &  scanquery ).fetch('event_end_time')\n",
    "auxgatetimestamp_start = (event.Event()  &  \"event_type='main_track_gate'\" &  scanquery ).fetch('event_start_time')\n",
    "\n",
    "# Then return FlashStim start timestamps within the recording gate only \n",
    "flashtimestamps = (event.Event()  &  \"event_type='arena_LED'\" & f\"event_start_time>{auxgatetimestamp_start[0]}\" & f\"event_start_time<{auxgatetimestamp_end[0]}\" & scanquery).fetch('event_start_time')\n",
    "\n",
    "#  and 2p timestamps (which will always be in the recording gate).\n",
    "twoptimestamps = (event.Event()  &  \"event_type='mini2p_frames'\" &  scanquery ).fetch('event_start_time')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flashtimestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get the 2p frame indices that correspond most closely to these timestamps\n",
    "flash_aligned_2pframes = get_closest_timestamps(flashtimestamps, twoptimestamps)\n",
    "\n",
    "# this should have the same shape as the 2p frames:\n",
    "print(np.shape(flash_aligned_2pframes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flash_aligned_2pframes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event.BehaviorRecording.File()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " dj.Diagram(event) +dj.Diagram(trial) + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# change to the upper level folder to detect dj_local_conf.json\n",
    "if os.path.basename(os.getcwd())=='notebooks': os.chdir('..')\n",
    "assert os.path.basename(os.getcwd())=='adamacs', (\"Please move to the main directory\")\n",
    "from adamacs.pipeline import subject, session, equipment, surgery, event, trial, imaging, scan, model\n",
    "from adamacs.ingest import session as isess\n",
    "from adamacs.helpers import stack_helpers as sh\n",
    "from adamacs.ingest import behavior as ibe\n",
    "import datajoint as dj\n",
    "from rspace_client.eln import eln\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "dj.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get latest dataset from Natasha from database\n",
    "2. load 2p movie to array. \n",
    "3. load top-video to array\n",
    "4. find the Start and end frames of the movie with respect to the tracking gate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "import cv2\n",
    "\n",
    "def get_closest_timestamps(series, target_timestamp):\n",
    "    # List to store the indices\n",
    "    indices = []\n",
    "\n",
    "    # For each timestamp in series1, find the closest timestamp in series2 and get its index\n",
    "    for t1 in series:\n",
    "        closest_index = closest_timestamp(target_timestamp, t1)\n",
    "        indices.append(closest_index)\n",
    "    return indices\n",
    "\n",
    "# Function to find closest timestamp\n",
    "def closest_timestamp(series, target_timestamp):\n",
    "    index = bisect.bisect_left(series, target_timestamp)\n",
    "    if index == 0:\n",
    "        return 0\n",
    "    if index == len(series):\n",
    "        return len(series)-1\n",
    "    before = series[index - 1]\n",
    "    after = series[index]\n",
    "    if after - target_timestamp < target_timestamp - before:\n",
    "       return index\n",
    "    else:\n",
    "       return index-1\n",
    "\n",
    "\n",
    "def resize_movie(movie, new_height, new_width):\n",
    "    # Get the number of frames and color channels\n",
    "    num_frames, _, _, num_channels = movie.shape\n",
    "    \n",
    "    # Initialize an empty array for the scaled movie\n",
    "    scaled_movie = np.empty((num_frames, new_height, new_width, num_channels), dtype=np.uint8)\n",
    "    \n",
    "    # Iterate through each frame\n",
    "    for i in tqdm(range(num_frames), desc=\"Resizing frames\"):\n",
    "        # Resize the frame and store it in the new array\n",
    "        scaled_movie[i] =  cv2.resize(movie[i], (new_width, new_height), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    # Return the scaled movie\n",
    "    return scaled_movie\n",
    "\n",
    "\n",
    "def resize_frame(frame, new_height, new_width):\n",
    "    return cv2.resize(frame, (new_width, new_height), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "def resize_movie_mt(movie, new_height, new_width):\n",
    "    num_frames, _, _, num_channels = movie.shape\n",
    "    scaled_movie = np.empty((num_frames, new_height, new_width, num_channels), dtype=np.uint8)\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        for i, resized_frame in tqdm(enumerate(executor.map(resize_frame, movie, [new_height]*num_frames, [new_width]*num_frames)), total=num_frames, desc=\"Resizing frames\"):\n",
    "            scaled_movie[i] = resized_frame\n",
    "\n",
    "    return scaled_movie\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "import concurrent.futures\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining queries - example for latest recording sessino of specific user\n",
    "\n",
    "# select user\n",
    "user = \"NK\"\n",
    "userquery = (session.SessionUser * subject.User() & f'initials = \"{user}\"')\n",
    "\n",
    "\n",
    "# get the latest session\n",
    "usesession = session.Session.fetch(order_by='session_datetime DESC', as_dict=True)[0][\"session_id\"]\n",
    "sessionquery = session.Session &  f'session_id = \"{usesession}\"'\n",
    "\n",
    "scansi = (scan.Scan & sessionquery).fetch('scan_id')[0]\n",
    "\n",
    "scanquery = scan.Scan & f'scan_id = \"{scansi}\"'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining queries - example for directly giving scan number\n",
    "\n",
    "\n",
    "scansi = \"scan9FHS7Y22\"\n",
    "\n",
    "scanquery = scan.Scan & f'scan_id = \"{scansi}\"'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluos = np.vstack((scanquery * imaging.Fluorescence.Trace).fetch(\"fluorescence\"))\n",
    "plt.figure(figsize=(16,12))\n",
    "plt.imshow(fluos, aspect='auto', cmap='gray_r')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MOVIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import skvideo.io\n",
    "\n",
    "# get the main data directory of the specified scanID \n",
    "\n",
    "dir = (scan.ScanPath & scanquery).fetch('path')\n",
    "\n",
    "# get the top cam movie of that session\n",
    "directory = Path(dir[0])\n",
    "pattern = '*top_video*.mp4'\n",
    "files = list(directory.glob(pattern))\n",
    "\n",
    "#load to array\n",
    "videodata = skvideo.io.vread(str(files[0]))\n",
    "videodata = np.asarray([skvideo.io.vshape(frame)[0] for frame in videodata], dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the registered moving average (blinking) movie data of the specified scanID\n",
    "directory = Path(dir[0] + \"/suite2p/plane0/reg_tif\")\n",
    "pattern = '*40_frame*.mp4'\n",
    "files = list(directory.glob(pattern))\n",
    "blinkvideodata = skvideo.io.vread(str(files[0]))\n",
    "blinkvideodata = np.asarray([skvideo.io.vshape(frame)[0] for frame in blinkvideodata], dtype=np.uint8)\n",
    "\n",
    "#dimensionts of the original movie (frames, x,y,rgb)\n",
    "print(videodata.shape)\n",
    "print(blinkvideodata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display camaravideo with slider\n",
    "sh.display_volume_z(videodata,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display 2pstackvideo with slider\n",
    "sh.display_volume_z(blinkvideodata,1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synchronization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the timestamp data and gate / offset cameraframes\n",
    "\n",
    "# from the event table get the main recording gate start / end timestamps.\n",
    "auxgatetimestamp_end = (event.Event()  &  \"event_type='main_track_gate'\" &  scanquery ).fetch('event_end_time')\n",
    "auxgatetimestamp_start = (event.Event()  &  \"event_type='main_track_gate'\" &  scanquery ).fetch('event_start_time')\n",
    "\n",
    "# Then return camera start timestamps within the recording gate only \n",
    "cameratimestamps = (event.Event()  &  \"event_type='aux_cam'\" & f\"event_start_time>{auxgatetimestamp_start[0]}\" & f\"event_start_time<{auxgatetimestamp_end[0]}\" & scanquery).fetch('event_start_time')\n",
    "\n",
    "#  and 2p timestamps (which will always be in the recording gate).\n",
    "twoptimestamps = (event.Event()  &  \"event_type='mini2p_frames'\" &  scanquery ).fetch('event_start_time')\n",
    "\n",
    "#  Zero camera timestamps on first 2p timestamp. (not necessary)\n",
    "# cameratimestamps = cameratimestamps - twoptimestamps[0]\n",
    "# twoptimestamps = twoptimestamps - twoptimestamps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event.EventType()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event.Event() & scanquery  &  \"event_type='aux_cam'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align the two recordings by finding the indices of the closest camera timestamp that fits the 2p frame timestamps by sorted list insertion (\"bisect\"). Be aware: camera frames can be double.\n",
    "aligned_cameraframes = get_closest_timestamps(twoptimestamps,cameratimestamps)\n",
    "\n",
    "# this should have the same shape as the 2p frames:\n",
    "print(np.shape(aligned_cameraframes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# now use this camara frame indices to reslice the video (which now is aligned to the 2p frames on a frame-by-frame level)\n",
    "resliced_cam_video = videodata[aligned_cameraframes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display synchronized movie\n",
    "sh.display_volume_z(resliced_cam_video,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale camera movie to fit size of 2p movie (can take a lot of time and memory)\n",
    "rescaled_cam_movie = resize_movie(resliced_cam_video, np.shape(blinkvideodata)[1],np.shape(blinkvideodata)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate and display movies\n",
    "concatmovie = np.concatenate((blinkvideodata,rescaled_cam_movie), axis = 2)\n",
    "sh.display_volume_z(concatmovie,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as new movie (without rescaling)\n",
    "\n",
    "\n",
    "filename = str(directory) + '/aligned_stack_cam_movie.mp4'\n",
    "fps = (scan.ScanInfo & scanquery).fetch('fps')\n",
    "# p1 = 0\n",
    "# p2 = 100\n",
    "# trash = sh.make_stack_movie(concatmovie, filename, fps[0], p1, p2)\n",
    "\n",
    "codecset = 'libx264'\n",
    "import imageio\n",
    "import imageio.plugins.ffmpeg as ffmpeg\n",
    "\n",
    "# Create an imageio VideoWriter object to write the video\n",
    "writer = imageio.get_writer(filename, fps=fps[0], codec=codecset, output_params=['-crf', '19'])\n",
    "\n",
    "# # Calculate the 1st and 99th percentile\n",
    "# p1, p99 = np.percentile(running_z_projection[:500,:,:], (p1set, p2set))\n",
    "\n",
    "# # rescale to 8 bit\n",
    "# rescaled_image_8bit = rescale_image_multithreaded(running_z_projection, p1, p99)\n",
    "\n",
    "for page in concatmovie:\n",
    "    writer.append_data(page)\n",
    "\n",
    "# Close the video writer\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speed up, add timestamps etc - all with fast ffmpeg operations\n",
    "\n",
    "import os\n",
    "\n",
    "spedby = 5\n",
    "setpts_value = 1/spedby # change this to your desired value\n",
    "newfps = fps[0]*spedby\n",
    "\n",
    "input_filename = filename\n",
    "# 2. Add timestamps\n",
    "\n",
    "output_filename = str(directory) + '/' + scansi + '_top_video_concatenated' + 'withtimestamps.mp4'\n",
    "command = f\"\"\"ffmpeg -y -i {input_filename} -vf \"drawtext=fontfile=/Library/Fonts/Arial.ttf:timecode='00\\\\\\\\:00\\\\\\\\:00\\\\\\\\:00':rate={fps[0]}:text='':fontsize=14:fontcolor=white:x=270:y=10:box=1:boxcolor=0x00000000@1\" -f mp4 {output_filename}\"\"\"\n",
    "\n",
    "os.system(command)\n",
    "\n",
    "\n",
    "input_filename = output_filename  # 'sped_up_video.mp4'\n",
    "output_filename = str(directory) + '/' +  scansi + '_top_video_concatenated_spedup_' + str(spedby) + 'fold_withtimestamps.mp4'\n",
    "\n",
    "command = f'ffmpeg -y -i {input_filename} -vf \"setpts={setpts_value}*PTS\" -r {newfps}  {output_filename}'\n",
    "\n",
    "\n",
    "\n",
    "os.system(command)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Synchronization of Flash stimulus with 2p data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event.EventType()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the timestamp data and gate / offset cameraframes\n",
    "\n",
    "# from the event table get the main recording gate start / end timestamps.\n",
    "auxgatetimestamp_end = (event.Event()  &  \"event_type='main_track_gate'\" &  scanquery ).fetch('event_end_time')\n",
    "auxgatetimestamp_start = (event.Event()  &  \"event_type='main_track_gate'\" &  scanquery ).fetch('event_start_time')\n",
    "\n",
    "# Then return FlashStim start timestamps within the recording gate only \n",
    "flashtimestamps = (event.Event()  &  \"event_type='arena_LED'\" & f\"event_start_time>{auxgatetimestamp_start[0]}\" & f\"event_start_time<{auxgatetimestamp_end[0]}\" & scanquery).fetch('event_start_time')\n",
    "\n",
    "#  and 2p timestamps (which will always be in the recording gate).\n",
    "twoptimestamps = (event.Event()  &  \"event_type='mini2p_frames'\" &  scanquery ).fetch('event_start_time')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flashtimestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get the 2p frame indices that correspond most closely to these timestamps\n",
    "flash_aligned_2pframes = get_closest_timestamps(flashtimestamps, twoptimestamps)\n",
    "\n",
    "# this should have the same shape as the 2p frames:\n",
    "print(np.shape(flash_aligned_2pframes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flash_aligned_2pframes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event.BehaviorRecording.File()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " dj.Diagram(event) +dj.Diagram(trial) + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

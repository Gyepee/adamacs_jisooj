{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-07-18 07:29:37,807][INFO]: Connecting tobiasr@172.26.128.53:3306\n",
      "[2023-07-18 07:29:37,853][INFO]: Connected tobiasr@172.26.128.53:3306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.14.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# change to the upper level folder to detect dj_local_conf.json\n",
    "if os.path.basename(os.getcwd())=='notebooks': os.chdir('..')\n",
    "assert os.path.basename(os.getcwd())=='adamacs', (\"Please move to the main directory\")\n",
    "from adamacs.pipeline import subject, session, equipment, surgery, event, trial, imaging, scan, model\n",
    "from adamacs.ingest import session as isess\n",
    "from adamacs.helpers import stack_helpers as sh\n",
    "from adamacs.ingest import behavior as ibe\n",
    "import datajoint as dj\n",
    "from rspace_client.eln import eln\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "dj.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get latest dataset from Natasha from database\n",
    "2. load 2p movie to array. \n",
    "3. load top-video to array\n",
    "4. find the Start and end frames of the movie with respect to the tracking gate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "import cv2\n",
    "\n",
    "def get_closest_timestamps(series, target_timestamp):\n",
    "    # List to store the indices\n",
    "    indices = []\n",
    "\n",
    "    # For each timestamp in series1, find the closest timestamp in series2 and get its index\n",
    "    for t1 in series:\n",
    "        closest_index = closest_timestamp(target_timestamp, t1)\n",
    "        indices.append(closest_index)\n",
    "    return indices\n",
    "\n",
    "# Function to find closest timestamp\n",
    "def closest_timestamp(series, target_timestamp):\n",
    "    index = bisect.bisect_left(series, target_timestamp)\n",
    "    if index == 0:\n",
    "        return 0\n",
    "    if index == len(series):\n",
    "        return len(series)-1\n",
    "    before = series[index - 1]\n",
    "    after = series[index]\n",
    "    if after - target_timestamp < target_timestamp - before:\n",
    "       return index\n",
    "    else:\n",
    "       return index-1\n",
    "\n",
    "\n",
    "def resize_movie(movie, new_height, new_width):\n",
    "    # Get the number of frames and color channels\n",
    "    num_frames, _, _, num_channels = movie.shape\n",
    "    \n",
    "    # Initialize an empty array for the scaled movie\n",
    "    scaled_movie = np.empty((num_frames, new_height, new_width, num_channels), dtype=np.uint8)\n",
    "    \n",
    "    # Iterate through each frame\n",
    "    for i in tqdm(range(num_frames), desc=\"Resizing frames\"):\n",
    "        # Resize the frame and store it in the new array\n",
    "        scaled_movie[i] =  cv2.resize(movie[i], (new_width, new_height), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    # Return the scaled movie\n",
    "    return scaled_movie\n",
    "\n",
    "\n",
    "def resize_frame(frame, new_height, new_width):\n",
    "    return cv2.resize(frame, (new_width, new_height), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "def resize_movie_mt(movie, new_height, new_width):\n",
    "    num_frames, _, _, num_channels = movie.shape\n",
    "    scaled_movie = np.empty((num_frames, new_height, new_width, num_channels), dtype=np.uint8)\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        for i, resized_frame in tqdm(enumerate(executor.map(resize_frame, movie, [new_height]*num_frames, [new_width]*num_frames)), total=num_frames, desc=\"Resizing frames\"):\n",
    "            scaled_movie[i] = resized_frame\n",
    "\n",
    "    return scaled_movie\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "import concurrent.futures\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining queries - example for latest recording sessino of specific user\n",
    "\n",
    "# select user\n",
    "user = \"NK\"\n",
    "userquery = (session.SessionUser * subject.User() & f'initials = \"{user}\"')\n",
    "\n",
    "\n",
    "# get the latest session\n",
    "usesession = session.Session.fetch(order_by='session_datetime DESC', as_dict=True)[0][\"session_id\"]\n",
    "sessionquery = session.Session &  f'session_id = \"{usesession}\"'\n",
    "\n",
    "scansi = (scan.Scan & sessionquery).fetch('scan_id')[0]\n",
    "\n",
    "scanquery = scan.Scan & f'scan_id = \"{scansi}\"'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining queries - example for directly giving scan number\n",
    "\n",
    "\n",
    "scansi = \"scan9FI3KWP3\"\n",
    "\n",
    "scanquery = scan.Scan & f'scan_id = \"{scansi}\"'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    <style type=\"text/css\">\n",
       "        .Table{\n",
       "            border-collapse:collapse;\n",
       "        }\n",
       "        .Table th{\n",
       "            background: #A0A0A0; color: #ffffff; padding:4px; border:#f0e0e0 1px solid;\n",
       "            font-weight: normal; font-family: monospace; font-size: 100%;\n",
       "        }\n",
       "        .Table td{\n",
       "            padding:4px; border:#f0e0e0 1px solid; font-size:100%;\n",
       "        }\n",
       "        .Table tr:nth-child(odd){\n",
       "            background: #ffffff;\n",
       "            color: #000000;\n",
       "        }\n",
       "        .Table tr:nth-child(even){\n",
       "            background: #f3f1ff;\n",
       "            color: #000000;\n",
       "        }\n",
       "        /* Tooltip container */\n",
       "        .djtooltip {\n",
       "        }\n",
       "        /* Tooltip text */\n",
       "        .djtooltip .djtooltiptext {\n",
       "            visibility: hidden;\n",
       "            width: 120px;\n",
       "            background-color: black;\n",
       "            color: #fff;\n",
       "            text-align: center;\n",
       "            padding: 5px 0;\n",
       "            border-radius: 6px;\n",
       "            /* Position the tooltip text - see examples below! */\n",
       "            position: absolute;\n",
       "            z-index: 1;\n",
       "        }\n",
       "        #primary {\n",
       "            font-weight: bold;\n",
       "            color: black;\n",
       "        }\n",
       "        #nonprimary {\n",
       "            font-weight: normal;\n",
       "            color: white;\n",
       "        }\n",
       "\n",
       "        /* Show the tooltip text when you mouse over the tooltip container */\n",
       "        .djtooltip:hover .djtooltiptext {\n",
       "            visibility: visible;\n",
       "        }\n",
       "    </style>\n",
       "    \n",
       "    <b>general data about the reso/meso scans from header</b>\n",
       "        <div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "        <table border=\"1\" class=\"Table\">\n",
       "            <thead> <tr style=\"text-align: right;\"> <th> <div class=\"djtooltip\">\n",
       "                            <p id=\"primary\">session_id</p>\n",
       "                            <span class=\"djtooltiptext\"></span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"primary\">scan_id</p>\n",
       "                            <span class=\"djtooltiptext\"></span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">nfields</p>\n",
       "                            <span class=\"djtooltiptext\">number of fields</span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">nchannels</p>\n",
       "                            <span class=\"djtooltiptext\">number of channels</span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">ndepths</p>\n",
       "                            <span class=\"djtooltiptext\">Number of scanning depths (planes)</span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">nframes</p>\n",
       "                            <span class=\"djtooltiptext\">number of recorded frames</span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">nrois</p>\n",
       "                            <span class=\"djtooltiptext\">number of ROIs (see scanimage's multi ROI imaging)</span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">x</p>\n",
       "                            <span class=\"djtooltiptext\">(um) ScanImage's 0 point in the motor coordinate system</span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">y</p>\n",
       "                            <span class=\"djtooltiptext\">(um) ScanImage's 0 point in the motor coordinate system</span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">z</p>\n",
       "                            <span class=\"djtooltiptext\">(um) ScanImage's 0 point in the motor coordinate system</span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">fps</p>\n",
       "                            <span class=\"djtooltiptext\">(Hz) frames per second - Volumetric Scan Rate</span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">bidirectional</p>\n",
       "                            <span class=\"djtooltiptext\">true = bidirectional scanning</span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">usecs_per_line</p>\n",
       "                            <span class=\"djtooltiptext\">microseconds per scan line</span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">fill_fraction</p>\n",
       "                            <span class=\"djtooltiptext\">raster scan temporal fill fraction (see scanimage)</span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">scan_datetime</p>\n",
       "                            <span class=\"djtooltiptext\">datetime of the scan</span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">scan_duration</p>\n",
       "                            <span class=\"djtooltiptext\">(seconds) duration of the scan</span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">userfunction_info</p>\n",
       "                            <span class=\"djtooltiptext\">string argument of file consolidation userfunction 1</span>\n",
       "                        </div> </th> </tr> </thead>\n",
       "            <tbody> <tr>  </tr> </tbody>\n",
       "        </table>\n",
       "        \n",
       "        <p>Total: 0</p></div>\n",
       "        "
      ],
      "text/plain": [
       "*session_id    *scan_id    nfields     nchannels     ndepths     nframes     nrois     x     y     z     fps     bidirectional  usecs_per_line fill_fraction  scan_datetime  scan_duration  userfunction_i\n",
       "+------------+ +---------+ +---------+ +-----------+ +---------+ +---------+ +-------+ +---+ +---+ +---+ +-----+ +------------+ +------------+ +------------+ +------------+ +------------+ +------------+\n",
       "\n",
       " (Total: 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scan.ScanInfo & scanquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/tobiasr/adamacs/notebooks/14_synchronization_examples_movie_IMU.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B172.26.128.53/home/tobiasr/adamacs/notebooks/14_synchronization_examples_movie_IMU.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m fluos \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mvstack((scanquery \u001b[39m*\u001b[39;49m imaging\u001b[39m.\u001b[39;49mFluorescence\u001b[39m.\u001b[39;49mTrace)\u001b[39m.\u001b[39;49mfetch(\u001b[39m\"\u001b[39;49m\u001b[39mfluorescence\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B172.26.128.53/home/tobiasr/adamacs/notebooks/14_synchronization_examples_movie_IMU.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m16\u001b[39m,\u001b[39m12\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B172.26.128.53/home/tobiasr/adamacs/notebooks/14_synchronization_examples_movie_IMU.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mimshow(fluos, aspect\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m, cmap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgray_r\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/datajoint/lib/python3.8/site-packages/numpy/core/shape_base.py:282\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(arrs, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    281\u001b[0m     arrs \u001b[39m=\u001b[39m [arrs]\n\u001b[0;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m _nx\u001b[39m.\u001b[39;49mconcatenate(arrs, \u001b[39m0\u001b[39;49m)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "fluos = np.vstack((scanquery * imaging.Fluorescence.Trace).fetch(\"fluorescence\"))\n",
    "plt.figure(figsize=(16,12))\n",
    "plt.imshow(fluos, aspect='auto', cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rastermap import Rastermap\n",
    "from scipy import stats \n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "ops = {'n_components': 1, 'n_X': 100, 'alpha': 1., 'K': 1.,\n",
    "            'nPC': 200, 'constraints': 2, 'annealing': True, 'init': 'pca',\n",
    "            'start_time': 0, 'end_time': -1}\n",
    "\n",
    "S = np.vstack(fluos)# deconvolved\n",
    "# S = nXp.vstack(fluorescence_traces)\n",
    "# we run rastermap the same way that the other scikit-learn embedding algorithms work\n",
    "# model = Rastermap(n_components=1, n_X=100, verbose = True).fit(S) \n",
    "model = Rastermap(n_components=ops['n_components'], n_X=ops['n_X'], nPC=ops['nPC'],\n",
    "                          init=ops['init'], alpha=ops['alpha'], K=ops['K'], constraints=ops['constraints'],\n",
    "                          annealing=ops['annealing'])\n",
    "model.fit(S)\n",
    "# def running_average(X, nbin = 10):\n",
    "#     Y = np.cumsum(X, axis=0)\n",
    "#     Y = Y[nbin:, :] - Y[:-nbin, :]\n",
    "#     return Y\n",
    "# the manifold embedding is in model.embedding\n",
    "isort = np.argsort(model.embedding[:,0])\n",
    "\n",
    "# sort by embedding and smooth over neurons\n",
    "# Sfilt = running_average(S[isort], 0)\n",
    "Sfilt = gaussian_filter1d(S[isort], np.minimum(8,np.maximum(1,int(S.shape[0]*0.001))),axis=0)\n",
    "# Sfilt = np.vstack(fluorescence_traces)\n",
    "Sfilt = stats.zscore(Sfilt, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,12))\n",
    "plt.imshow(Sfilt, vmin = -0.1, vmax=4, aspect='auto', cmap='gray_r')\n",
    "plt.xlabel('time points')\n",
    "plt.ylabel('sorted neurons')\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MOVIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import skvideo.io\n",
    "\n",
    "# get the main data directory of the specified scanID \n",
    "\n",
    "dir = (scan.ScanPath & scanquery).fetch('path')\n",
    "\n",
    "# get the top cam movie of that session\n",
    "directory = Path(dir[0])\n",
    "pattern = '*top_video*.mp4'\n",
    "files = list(directory.glob(pattern))\n",
    "\n",
    "#load to array\n",
    "videodata = skvideo.io.vread(str(files[0]))\n",
    "videodata = np.asarray([skvideo.io.vshape(frame)[0] for frame in videodata], dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the registered moving average (blinking) movie data of the specified scanID\n",
    "directory = Path(dir[0] + \"/suite2p/plane0/reg_tif\")\n",
    "pattern = '*20_frame*.mp4'\n",
    "files = list(directory.glob(pattern))\n",
    "blinkvideodata = skvideo.io.vread(str(files[0]))\n",
    "blinkvideodata = np.asarray([skvideo.io.vshape(frame)[0] for frame in blinkvideodata], dtype=np.uint8)\n",
    "\n",
    "#dimensionts of the original movie (frames, x,y,rgb)\n",
    "print(videodata.shape)\n",
    "print(blinkvideodata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display camaravideo with slider\n",
    "sh.display_volume_z(videodata,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display 2pstackvideo with slider\n",
    "sh.display_volume_z(blinkvideodata,1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synchronization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the timestamp data and gate / offset cameraframes\n",
    "\n",
    "# from the event table get the main recording gate start / end timestamps.\n",
    "auxgatetimestamp_end = (event.Event()  &  \"event_type='main_track_gate'\" &  scanquery ).fetch('event_end_time')\n",
    "auxgatetimestamp_start = (event.Event()  &  \"event_type='main_track_gate'\" &  scanquery ).fetch('event_start_time')\n",
    "\n",
    "# Then return camera start timestamps within the recording gate only \n",
    "cameratimestamps = (event.Event()  &  \"event_type='aux_cam'\" & f\"event_start_time>{auxgatetimestamp_start[0]}\" & f\"event_start_time<{auxgatetimestamp_end[0]}\" & scanquery).fetch('event_start_time')\n",
    "\n",
    "#  and 2p timestamps (which will always be in the recording gate).\n",
    "twoptimestamps = (event.Event()  &  \"event_type='mini2p_frames'\" &  scanquery ).fetch('event_start_time')\n",
    "\n",
    "twoptimestamps =  twoptimestamps[:np.shape(blinkvideodata)[0]] # truncating 2p timestamps to number of 2p videoframes\n",
    "\n",
    "#  Zero camera timestamps on first 2p timestamp. (not necessary)\n",
    "# cameratimestamps = cameratimestamps - twoptimestamps[0]\n",
    "# twoptimestamps = twoptimestamps - twoptimestamps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event.Event() & scanquery  &  \"event_type='aux_cam'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align the two recordings by finding the indices of the closest camera timestamp that fits the 2p frame timestamps by sorted list insertion (\"bisect\"). Be aware: camera frames can be double.\n",
    "aligned_cameraframes = get_closest_timestamps(twoptimestamps,cameratimestamps)\n",
    "\n",
    "# this should have the same shape as the 2p frames:\n",
    "print(np.shape(aligned_cameraframes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# now use this camara frame indices to reslice the video (which now is aligned to the 2p frames on a frame-by-frame level)\n",
    "resliced_cam_video = videodata[aligned_cameraframes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display synchronized movie\n",
    "sh.display_volume_z(resliced_cam_video,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale camera movie to fit size of 2p movie (can take a lot of time and memory)\n",
    "rescaled_cam_movie = resize_movie(resliced_cam_video, np.shape(blinkvideodata)[1],np.shape(blinkvideodata)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(rescaled_cam_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate and display movies\n",
    "concatmovie = np.concatenate((blinkvideodata,rescaled_cam_movie), axis = 2)\n",
    "sh.display_volume_z(concatmovie,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as new movie (without rescaling)\n",
    "\n",
    "\n",
    "filename = str(directory) + '/aligned_stack_cam_movie.mp4'\n",
    "fps = (scan.ScanInfo & scanquery).fetch('fps')\n",
    "# p1 = 0\n",
    "# p2 = 100\n",
    "# trash = sh.make_stack_movie(concatmovie, filename, fps[0], p1, p2)\n",
    "\n",
    "codecset = 'libx264'\n",
    "import imageio\n",
    "import imageio.plugins.ffmpeg as ffmpeg\n",
    "\n",
    "# Create an imageio VideoWriter object to write the video\n",
    "writer = imageio.get_writer(filename, fps=fps[0], codec=codecset, output_params=['-crf', '19'])\n",
    "\n",
    "# # Calculate the 1st and 99th percentile\n",
    "# p1, p99 = np.percentile(running_z_projection[:500,:,:], (p1set, p2set))\n",
    "\n",
    "# # rescale to 8 bit\n",
    "# rescaled_image_8bit = rescale_image_multithreaded(running_z_projection, p1, p99)\n",
    "\n",
    "for page in concatmovie:\n",
    "    writer.append_data(page)\n",
    "\n",
    "# Close the video writer\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speed up, add timestamps etc - all with fast ffmpeg operations\n",
    "\n",
    "import os\n",
    "\n",
    "spedby = 5\n",
    "setpts_value = 1/spedby # change this to your desired value\n",
    "newfps = fps[0]*spedby\n",
    "\n",
    "input_filename = filename\n",
    "# 2. Add timestamps\n",
    "\n",
    "output_filename = str(directory) + '/' + scansi + '_top_video_concatenated' + 'withtimestamps.mp4'\n",
    "command = f\"\"\"ffmpeg -y -i {input_filename} -vf \"drawtext=fontfile=/Library/Fonts/Arial.ttf:timecode='00\\\\\\\\:00\\\\\\\\:00\\\\\\\\:00':rate={fps[0]}:text='':fontsize=20:fontcolor=white:x=530:y=20:box=1:boxcolor=0x00000000@1\" -f mp4 {output_filename}\"\"\"\n",
    "\n",
    "os.system(command)\n",
    "\n",
    "\n",
    "input_filename = output_filename  # 'sped_up_video.mp4'\n",
    "output_filename = str(directory) + '/' +  scansi + '_top_video_concatenated_spedup_' + str(spedby) + 'fold_withtimestamps.mp4'\n",
    "\n",
    "command = f'ffmpeg -y -i {input_filename} -vf \"setpts={setpts_value}*PTS\" -r {newfps}  {output_filename}'\n",
    "\n",
    "\n",
    "\n",
    "os.system(command)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Synchronization of Flash stimulus with 2p data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event.EventType()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the timestamp data and gate / offset cameraframes\n",
    "\n",
    "# from the event table get the main recording gate start / end timestamps.\n",
    "auxgatetimestamp_end = (event.Event()  &  \"event_type='main_track_gate'\" &  scanquery ).fetch('event_end_time')\n",
    "auxgatetimestamp_start = (event.Event()  &  \"event_type='main_track_gate'\" &  scanquery ).fetch('event_start_time')\n",
    "\n",
    "# Then return FlashStim start timestamps within the recording gate only \n",
    "flashtimestamps = (event.Event()  &  \"event_type='arena_LED'\" & f\"event_start_time>{auxgatetimestamp_start[0]}\" & f\"event_start_time<{auxgatetimestamp_end[0]}\" & scanquery).fetch('event_start_time')\n",
    "\n",
    "#  and 2p timestamps (which will always be in the recording gate).\n",
    "twoptimestamps = (event.Event()  &  \"event_type='mini2p_frames'\" &  scanquery ).fetch('event_start_time')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flashtimestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get the 2p frame indices that correspond most closely to these timestamps\n",
    "flash_aligned_2pframes = get_closest_timestamps(flashtimestamps, twoptimestamps)\n",
    "\n",
    "# this should have the same shape as the 2p frames:\n",
    "print(np.shape(flash_aligned_2pframes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flash_aligned_2pframes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event.BehaviorRecording.File()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " dj.Diagram(event) +dj.Diagram(trial) + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-11-15 16:59:17,029][INFO]: Connecting tobiasr@172.26.128.53:3306\n",
      "[2023-11-15 16:59:17,077][INFO]: Connected tobiasr@172.26.128.53:3306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.14.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# change to the upper level folder to detect dj_local_conf.json\n",
    "if os.path.basename(os.getcwd())=='notebooks': os.chdir('..')\n",
    "assert os.path.basename(os.getcwd())=='adamacs', (\"Please move to the main directory\")\n",
    "from adamacs.pipeline import subject, session, equipment, surgery, event, trial, imaging, behavior, scan, model\n",
    "from adamacs.ingest import session as isess\n",
    "from adamacs.helpers import stack_helpers as sh\n",
    "from adamacs.helpers import trace_helpers as th\n",
    "from adamacs.ingest import behavior as ibe\n",
    "import datajoint as dj\n",
    "from rspace_client.eln import eln\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "dj.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some functions used here (will be hidden later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "import cv2\n",
    "\n",
    "def get_closest_timestamps(series, target_timestamp):\n",
    "    # List to store the indices\n",
    "    indices = []\n",
    "\n",
    "    # For each timestamp in series1, find the closest timestamp in series2 and get its index\n",
    "    for t1 in series:\n",
    "        closest_index = closest_timestamp(target_timestamp, t1)\n",
    "        indices.append(closest_index)\n",
    "    return indices\n",
    "\n",
    "# Function to find closest timestamp\n",
    "def closest_timestamp(series, target_timestamp):\n",
    "    index = bisect.bisect_left(series, target_timestamp)\n",
    "    if index == 0:\n",
    "        return 0\n",
    "    if index == len(series):\n",
    "        return len(series)-1\n",
    "    before = series[index - 1]\n",
    "    after = series[index]\n",
    "    if after - target_timestamp < target_timestamp - before:\n",
    "       return index\n",
    "    else:\n",
    "       return index-1\n",
    "\n",
    "\n",
    "def resize_movie(movie, new_height, new_width):\n",
    "    # Get the number of frames and color channels\n",
    "    num_frames, _, _, num_channels = movie.shape\n",
    "    \n",
    "    # Initialize an empty array for the scaled movie\n",
    "    scaled_movie = np.empty((num_frames, new_height, new_width, num_channels), dtype=np.uint8)\n",
    "    \n",
    "    # Iterate through each frame\n",
    "    for i in tqdm(range(num_frames), desc=\"Resizing frames\"):\n",
    "        # Resize the frame and store it in the new array\n",
    "        scaled_movie[i] =  cv2.resize(movie[i], (new_width, new_height), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    # Return the scaled movie\n",
    "    return scaled_movie\n",
    "\n",
    "\n",
    "def resize_frame(frame, new_height, new_width):\n",
    "    return cv2.resize(frame, (new_width, new_height), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "def resize_movie_mt(movie, new_height, new_width):\n",
    "    num_frames, _, _, num_channels = movie.shape\n",
    "    scaled_movie = np.empty((num_frames, new_height, new_width, num_channels), dtype=np.uint8)\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        for i, resized_frame in tqdm(enumerate(executor.map(resize_frame, movie, [new_height]*num_frames, [new_width]*num_frames)), total=num_frames, desc=\"Resizing frames\"):\n",
    "            scaled_movie[i] = resized_frame\n",
    "\n",
    "    return scaled_movie\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "import concurrent.futures\n",
    "\n",
    "\n",
    "# Figure Style settings for notebook.\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "plot_params = {\n",
    "    'axes.facecolor': 'white',\n",
    "    'figure.facecolor': 'white',\n",
    "    'font.family': 'sans-serif',\n",
    "    # 'font.sans-serif': 'Helvetica Neue',\n",
    "    'font.size': 16,\n",
    "    'lines.color': 'black',\n",
    "    'xtick.direction': 'out',\n",
    "    'ytick.direction': 'out',\n",
    "    'xtick.color': 'black',\n",
    "    'ytick.color': 'black',\n",
    "    'axes.spines.left': True,\n",
    "    'axes.spines.bottom': True,\n",
    "    'axes.spines.top': True,\n",
    "    'axes.spines.right': True,\n",
    "    'axes.edgecolor': 'black',  \n",
    "    # 'legend.frameon': False,\n",
    "    'figure.subplot.wspace': .5,\n",
    "    'figure.subplot.hspace': .5,\n",
    "    # 'figure.figsize': (18, 13),\n",
    "    'ytick.major.left': True,\n",
    "    'xtick.major.bottom': True\n",
    "}\n",
    "\n",
    "map_params = {\n",
    "    'axes.facecolor': 'white',\n",
    "    'figure.facecolor': 'white',\n",
    "    'font.family': 'sans-serif',\n",
    "    # 'font.sans-serif': 'Helvetica Neue',\n",
    "    'font.size': 12,\n",
    "    'lines.color': 'black',\n",
    "    'xtick.direction': 'out',\n",
    "    'ytick.direction': 'out',\n",
    "    'xtick.color': 'black',\n",
    "    'ytick.color': 'black',\n",
    "    'axes.spines.left': False,\n",
    "    'axes.spines.bottom': False,\n",
    "    'axes.spines.top': False,\n",
    "    'axes.spines.right': False,\n",
    "    'axes.edgecolor': 'black',  \n",
    "    # 'legend.frameon': False,\n",
    "    'figure.subplot.wspace': .5,\n",
    "    'figure.subplot.hspace': .5,\n",
    "    # 'figure.figsize': (18, 13),\n",
    "    'ytick.major.left': False,\n",
    "    'xtick.major.bottom': False\n",
    "}\n",
    "\n",
    "\n",
    "img_params = {\n",
    "    'axes.titlecolor': 'white',\n",
    "    'axes.facecolor': 'black',\n",
    "    'figure.facecolor': 'black',\n",
    "    'axes.spines.left': False,\n",
    "    'axes.spines.bottom': False,\n",
    "    'axes.spines.top': False,\n",
    "    'axes.spines.right': False,\n",
    "    'legend.frameon': False,\n",
    "    'figure.subplot.wspace': .01,\n",
    "    'figure.subplot.hspace': .01,\n",
    "    'figure.figsize': (18, 13),\n",
    "    'ytick.major.left': False,\n",
    "    'xtick.major.bottom': False\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recordings and example analysis for BonnBrain - RUKHMANI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rukhmani - example scans\n",
    "\n",
    "# mini2p\n",
    "# sessi = sess9FHELAYA\n",
    "# sess9FHDA7AI\n",
    "# scan9FI8ALGO\n",
    "\n",
    "# bench2p\n",
    "# sessi = sess9FJ66OT2\n",
    "# scan9FGLE1FN\n",
    "# scan9FGLEFJ3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bench2p figures and examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# first define a key to be used across multiple tables\u001b[39;00m\n\u001b[1;32m      3\u001b[0m scansi \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscan9FKWTLNS\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m scan_key \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mscan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mScan\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscan_id = \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mscansi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mKEY\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      5\u001b[0m session_key \u001b[38;5;241m=\u001b[39m (session\u001b[38;5;241m.\u001b[39mSession \u001b[38;5;241m&\u001b[39m scan_key)\u001b[38;5;241m.\u001b[39mfetch(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKEY\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      6\u001b[0m curation_key \u001b[38;5;241m=\u001b[39m (imaging\u001b[38;5;241m.\u001b[39mCuration \u001b[38;5;241m&\u001b[39m scan_key \u001b[38;5;241m&\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuration_id=1\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mfetch(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKEY\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# first define a key to be used across multiple tables\n",
    "\n",
    "scansi = \"scan9FKWTLNS\"\n",
    "scan_key = (scan.Scan & f'scan_id = \"{scansi}\"').fetch('KEY')[0]\n",
    "session_key = (session.Session & scan_key).fetch('KEY')[0]\n",
    "curation_key = (imaging.Curation & scan_key & 'curation_id=1').fetch('KEY')[0]\n",
    "sessi = (scan.Scan & f'scan_id = \"{scansi}\"').fetch('session_id')[0]\n",
    "aux_setup_typestr = (scan.ScanInfo() & scan_key).fetch(\"userfunction_info\")[0] # check setup type (not needed)\n",
    "print(aux_setup_typestr)\n",
    "print((scan.ScanPath & scan_key).fetch(\"path\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scan_key' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m (imaging\u001b[38;5;241m.\u001b[39mCuration \u001b[38;5;241m&\u001b[39m \u001b[43mscan_key\u001b[49m \u001b[38;5;241m&\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuration_id=1\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mfetch(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKEY\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scan_key' is not defined"
     ]
    }
   ],
   "source": [
    "(imaging.Curation & scan_key & 'curation_id=1').fetch('KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get and show overview images from suite2p registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_image = (imaging.MotionCorrection.Summary & curation_key & 'field_idx=0').fetch1('ref_image')\n",
    "average_image = (imaging.MotionCorrection.Summary & curation_key & 'field_idx=0').fetch1('average_image')\n",
    "correlation_image = (imaging.MotionCorrection.Summary & curation_key & 'field_idx=0').fetch1('correlation_image')\n",
    "max_proj_image = (imaging.MotionCorrection.Summary & curation_key & 'field_idx=0').fetch1('max_proj_image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some scaling values from pixel distribution\n",
    "scalemin = 0\n",
    "scalemax = 100\n",
    "\n",
    "cmin = np.percentile(average_image,scalemin)  \n",
    "cmax = np.percentile(average_image,scalemax)\n",
    "\n",
    "# load image styles for display\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "mpl.rcParams.update(img_params)\n",
    "\n",
    "# Make figure with all templates\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(ref_image, cmap='gray', vmin = cmin, vmax = cmax)\n",
    "plt.title(\"Reference Image for Registration\");\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(average_image, cmap='gray', vmin = cmin, vmax = cmax)\n",
    "plt.title(\"Registered Image, Mean Projection\");\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(max_proj_image, cmap='gray')\n",
    "plt.title(\"Registered Image, Max Projection\")\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(correlation_image, cmap='gray')\n",
    "plt.title(\"Registered Image, Correlation Map\")\n",
    "plt.show(block=False)\n",
    "plt.suptitle(scansi)\n",
    "# plt.savefig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just mean image\n",
    "scalemin = 1\n",
    "scalemax = 99\n",
    "\n",
    "cmin = np.percentile(average_image,scalemin)  \n",
    "cmax = np.percentile(average_image,scalemax)\n",
    "\n",
    "\n",
    "# plt.subplot(1, 4, 1)\n",
    "plt.imshow(average_image, cmap='gray', vmin = cmin, vmax = cmax)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot treadmill data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract scan treadmill data from database using the scan_key from above\n",
    "treadmill = (behavior.TreadmillRecording.Channel() & scan_key).fetch(\"data\")[0]\n",
    "auxtime = (behavior.TreadmillRecording.Channel() & scan_key).fetch(\"time\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smoothing window size (ms)\n",
    "window = 5000\n",
    "\n",
    "# convert voltage to degree\n",
    "treadmillnorm = (treadmill-np.min(treadmill)) / np.max(treadmill) * 360\n",
    "\n",
    "# compute running speed (see function above)\n",
    "angular_velocity_smoothed, unwrapped_angle_smoothed = ibe.compute_angular_velocity(auxtime, treadmillnorm, window)\n",
    "\n",
    "# get some values to scale running speed plot \n",
    "scalemin = 0\n",
    "scalemax = 100\n",
    "offset = 10\n",
    "ymin = np.percentile(angular_velocity_smoothed,scalemin)  - offset\n",
    "ymax = np.percentile(angular_velocity_smoothed,scalemax)  + offset\n",
    "\n",
    "# load plot styles for display\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "mpl.rcParams.update(plot_params)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(15, 10))\n",
    "# plt.rcParams['agg.path.chunksize'] = 10000  # Add this line if it does not rende\n",
    "\n",
    "# Plotting the time series\n",
    "axes[0].plot(auxtime, treadmillnorm)\n",
    "axes[0].set_ylim([-10, 370])\n",
    "axes[0].set_ylabel(\"Wheel position \\n[degree]\")\n",
    "axes[0].set_xlabel(\"Time [s]\")\n",
    "\n",
    "axes[1].plot(auxtime[:-window+1],unwrapped_angle_smoothed )\n",
    "# axes[1].set_ylim([-10000, 10000])\n",
    "axes[1].set_ylabel(\"Unwrapped wheel position \\n[cumulative degree]\")\n",
    "axes[1].set_xlabel(\"Time [s]\")\n",
    "\n",
    "axes[2].plot(auxtime[:-window],angular_velocity_smoothed)\n",
    "axes[2].set_ylim([ymin, ymax])\n",
    "axes[2].set_ylabel(\"Running speed \\n[degree / s]\")\n",
    "axes[2].set_xlabel(\"Time [s]\")\n",
    "\n",
    "fig.suptitle(scan_key[\"scan_id\"], fontsize=16)\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the fluorescence traces of this recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mask positions of masks that are classified as cells and that are larger than a certain pixel size\n",
    "mask_xpix, mask_ypix = (\n",
    "    imaging.Segmentation.Mask * imaging.MaskClassification.MaskType\n",
    "    & scan_key\n",
    "    & \"mask_npix > 30\"\n",
    ").fetch(\"mask_xpix\", \"mask_ypix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this query, we've fetched the coordinates of segmented masks. We can overlay these\n",
    "masks onto our average image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_image = np.zeros(np.shape(average_image), dtype=bool)\n",
    "for xpix, ypix in zip(mask_xpix, mask_ypix):\n",
    "    mask_image[ypix, xpix] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image styles for display\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "mpl.rcParams.update(img_params)\n",
    "\n",
    "plt.imshow(average_image, cmap='gray', vmin = cmin, vmax = cmax)\n",
    "plt.contour(mask_image, colors=\"red\", linewidths=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more example using queries - plot fluorescence and deconvolved activity\n",
    "traces:\n",
    "\n",
    "Here we fetch the primary key attributes of the entry with `curation_id=0` for the\n",
    "current session in the `imaging.Curation` table. \n",
    "\n",
    "Then, we fetch all cells that fit the\n",
    "restriction criteria from `imaging.Segmentation.Mask` and\n",
    "`imaging.MaskClassification.MaskType` as a `projection`. \n",
    "\n",
    "We then use this projection as\n",
    "a restriction to fetch and plot fluorescence and deconvolved activity traces from the\n",
    "`imaging.Fluorescence.Trace` and `imaging.Activity.Trace` tables, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curation_key = (imaging.Curation & scan_key & curation_key).fetch1(\"KEY\")\n",
    "query_cells = (\n",
    "    imaging.Segmentation.Mask * imaging.MaskClassification.MaskType\n",
    "    & curation_key\n",
    "    & \"mask_center_z=0\"\n",
    "    & \"mask_npix > 30\"\n",
    ").proj()\n",
    "\n",
    "# query_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuropilcorr = True\n",
    "\n",
    "fluorescence_traces = (imaging.Fluorescence.Trace & query_cells).fetch(\n",
    "    \"fluorescence\", order_by=\"mask\"\n",
    ")\n",
    "\n",
    "neuropil_traces = (imaging.Fluorescence.Trace & query_cells).fetch(\n",
    "    \"neuropil_fluorescence\", order_by=\"mask\"\n",
    ")\n",
    "\n",
    "if neuropilcorr:\n",
    "    print(\"DOING VANILLA NEUROPIL CORRECTION NOW!\")\n",
    "    fluorescence_traces = fluorescence_traces - 0.7 * neuropil_traces\n",
    "\n",
    "activity_traces = (imaging.Activity.Trace & query_cells).fetch(\n",
    "    \"activity_trace\", order_by=\"mask\"\n",
    ")\n",
    "\n",
    "sampling_rate = (scan.ScanInfo & curation_key).fetch1(\"fps\")\n",
    "\n",
    "# timebase_2p = np.r_[: fluorescence_traces[0].size] * 1 / sampling_rate\n",
    "\n",
    "timebase_2p = np.linspace(0, fluorescence_traces[0].size / sampling_rate, fluorescence_traces[0].shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rastermap import Rastermap\n",
    "from scipy import stats \n",
    "from scipy.stats import zscore\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "\n",
    "\n",
    "# stack fluorescence for rastermap\n",
    "fluos = np.vstack(fluorescence_traces)\n",
    "\n",
    "nan_mask = np.isnan(fluos).any(axis=1)\n",
    "\n",
    "# Create a mask for rows containing only zeros\n",
    "zero_rows = np.all(fluos == 0, axis=1)\n",
    "\n",
    "# Create a mask for rows containing only inf\n",
    "inf_rows = np.all(np.isinf(fluos), axis=1)\n",
    "\n",
    "# Create a mask for rows containing only NaN\n",
    "nan_rows = np.all(np.isnan(fluos), axis=1)\n",
    "\n",
    "# Combine the masks using logical OR\n",
    "mask_to_remove = zero_rows | inf_rows | nan_rows | nan_mask\n",
    "\n",
    "S = fluos[~mask_to_remove]\n",
    "S = zscore(S, axis=1)\n",
    "\n",
    "rmmodel = Rastermap(n_clusters=100, # None turns off clustering and sorts single neurons \n",
    "                  n_PCs=10, # use fewer PCs than neurons\n",
    "                  locality=0.15, # some locality in sorting (this is a value from 0-1)\n",
    "                  time_lag_window=15, # use future timepoints to compute correlation\n",
    "                  grid_upsample=0, # 0 turns off upsampling since we're using single neurons\n",
    "                ).fit(S)\n",
    "\n",
    "\n",
    "y = rmmodel.embedding # neurons x 1\n",
    "isort = rmmodel.isort\n",
    "\n",
    "# sort by embedding and smooth over neurons (uncomment)\n",
    "\n",
    "# Sfilt = gaussian_filter1d(S[isort], np.minimum(1,np.maximum(1,int(S.shape[0]*0.001))),axis=0)\n",
    "Sfilt = S[isort]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sorted data\n",
    "# load plot styles for display\n",
    "\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "mpl.rcParams.update(plot_params)\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.imshow(Sfilt, vmin = -0.1, vmax=1, extent= [timebase_2p[0], timebase_2p[-1], 0, Sfilt.shape[0]], aspect='auto', cmap='gray_r')\n",
    "plt.xlabel('time [s]')\n",
    "plt.ylabel('sorted neurons')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "figure = plt.figure(figsize=(15,15))\n",
    "ax = figure.add_subplot(111)\n",
    "\n",
    "offset_scaler = 10 # We want to plot every cell with a little offset to the last one\n",
    "for no,trace in enumerate(Sfilt):\n",
    "    if no == 80: break # not more than 80\n",
    "\n",
    "    # get the neuropil corrected values for that trace:\n",
    "    # trace = Sfilt\n",
    "    ax.plot(timebase_2p,trace + (no*offset_scaler),lw=1,c='k',alpha=.8)\n",
    "\n",
    "ax.set_xlim(0,timebase_2p[-1])\n",
    "\n",
    "ax.get_yaxis().set_ticks([])\n",
    "ax.set_title('Sorted z-scored traces')    \n",
    "\n",
    "ax.set_ylabel('Cells')\n",
    "ax.set_xlabel('Time [s]')\n",
    "sns.despine(left=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synchronization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and 2p timestamps (which will always be in the recording gate).\n",
    "twoptimestamps = (event.Event()  &  \"event_type='bench2p_frames'\" &  scan_key ).fetch('event_start_time')\n",
    "aligned_wheel_indices = get_closest_timestamps(twoptimestamps,auxtime[:-window]) #smoothing windwo from above\n",
    "\n",
    "# use this to index into the wheelspeed\n",
    "angular_velocity_smoothed_2pref = angular_velocity_smoothed[aligned_wheel_indices]\n",
    "\n",
    "# both arrays have same shape now - now 2pdata and wheel speed can be plotted together on the 2ptimestamps\n",
    "print(np.shape(twoptimestamps))\n",
    "print(np.shape(angular_velocity_smoothed_2pref))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_colors = np.array([[0.55,0.55,0.55]])\n",
    "\n",
    "\n",
    "# timepoints to visualize\n",
    "tstart = 0\n",
    "tend =  timebase_2p[-1] - 10\n",
    "\n",
    "xmin = int(np.floor(tstart * sampling_rate))\n",
    "xmax = int(np.floor(tend * sampling_rate))\n",
    "\n",
    "# make figure with grid for easy plotting\n",
    "fig = plt.figure(figsize=(8,5), dpi=200)\n",
    "grid = plt.GridSpec(9, 20, figure=fig, wspace = 0.05, hspace = 0.3)\n",
    "\n",
    "# plot running speed\n",
    "ax = plt.subplot(grid[:2, :-1])\n",
    "ax.plot(angular_velocity_smoothed_2pref,  color=kp_colors[0])\n",
    "ax.set_xlim([0, xmax-xmin])\n",
    "ax.axis(\"off\")\n",
    "ax.set_title(\"running speed\", color=kp_colors[0])\n",
    "# ax.set_xlabel(\"running speed\")\n",
    "\n",
    "# plot superneuron activity\n",
    "ax = plt.subplot(grid[2:, :-1])\n",
    "ax.imshow(Sfilt[:, xmin:xmax], cmap=\"gray_r\", vmin=-0.1, vmax=0.7,  extent= [timebase_2p[xmin], timebase_2p[xmax], 0, Sfilt.shape[0]], aspect=\"auto\")\n",
    "ax.set_xlabel(\"time [s]\")\n",
    "ax.set_ylabel(\"sorted neurons\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# ax = plt.subplot(grid[1:, -1])\n",
    "# ax.imshow(np.arange(0, len(sn))[:,np.newaxis], cmap=\"gist_ncar\", aspect=\"auto\")\n",
    "# ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini2p figures and examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first define a key to be used across multiple tables\n",
    "\n",
    "# scansi = \"scan9FI8ALGO\"\n",
    "# scansi = \"scan9FKNVVH5\"\n",
    "scansi = \"scan9FKWT95S\"\n",
    "\n",
    "scan_key = (scan.Scan & f'scan_id = \"{scansi}\"').fetch('KEY')[0]\n",
    "curation_key = (imaging.Curation & scan_key & 'curation_id=1').fetch1('KEY')\n",
    "sessi = (scan.Scan & f'scan_id = \"{scansi}\"').fetch('session_id')[0]\n",
    "session_key = (session.Session & f'session_id = \"{sessi}\"').fetch('KEY')[0]\n",
    "aux_setup_typestr = (scan.ScanInfo() & scan_key).fetch(\"userfunction_info\")[0] # check setup type (not needed)\n",
    "print(aux_setup_typestr)\n",
    "print((scan.ScanPath & scan_key).fetch(\"path\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.Session * subject.Subject & session_key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan.Scan * scan.ScanInfo * session.SessionSameSite * session.Session() & session_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get and show overview images from suite2p registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_image = (imaging.MotionCorrection.Summary & curation_key & 'field_idx=0').fetch1('ref_image')\n",
    "average_image = (imaging.MotionCorrection.Summary & curation_key & 'field_idx=0').fetch1('average_image')\n",
    "correlation_image = (imaging.MotionCorrection.Summary & curation_key & 'field_idx=0').fetch1('correlation_image')\n",
    "max_proj_image = (imaging.MotionCorrection.Summary & curation_key & 'field_idx=0').fetch1('max_proj_image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some scaling values from pixel distribution\n",
    "scalemin = 0\n",
    "scalemax = 100\n",
    "offset = 0\n",
    "\n",
    "\n",
    "cmin = np.percentile(average_image,scalemin)  \n",
    "cmax = np.percentile(average_image,scalemax) + offset\n",
    "\n",
    "# load image styles for display\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "mpl.rcParams.update(img_params)\n",
    "\n",
    "# Make figure with all templates\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(ref_image, cmap='gray', vmin = cmin, vmax = cmax)\n",
    "plt.title(\"Reference Image for Registration\");\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(average_image, cmap='gray', vmin = cmin, vmax = cmax)\n",
    "plt.title(\"Registered Image, Mean Projection\");\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(max_proj_image, cmap='gray')\n",
    "plt.title(\"Registered Image, Max Projection\")\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(correlation_image, cmap='gray')\n",
    "plt.title(\"Registered Image, Correlation Map\")\n",
    "plt.show(block=False)\n",
    "# plt.savefig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just mean image\n",
    "scalemin = 1\n",
    "scalemax = 99\n",
    "\n",
    "cmin = np.percentile(average_image,scalemin) \n",
    "cmax = np.percentile(average_image,scalemax) #+ offset\n",
    "\n",
    "\n",
    "# plt.subplot(1, 4, 1)\n",
    "plt.imshow(average_image, cmap='gray', vmin = cmin, vmax = cmax)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make cam-synchronized movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import skvideo.io\n",
    "\n",
    "# get the movie file name from the database\n",
    "topfile = (model.VideoRecording.File & scan_key).fetch('file_path')[0]\n",
    "\n",
    "#load to array\n",
    "videodata = skvideo.io.vread(str(topfile))\n",
    "# videodata = np.asarray([skvideo.io.vshape(frame)[0] for frame in videodata], dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make DLC overlay video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.PoseEstimationTask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "key =  (model.PoseEstimationTask & f'recording_id=\"{scansi}\"').fetch1('KEY')\n",
    "destfolder = (model.PoseEstimationTask & key).fetch1('pose_estimation_output_dir')\n",
    "\n",
    "labeled_videofile = glob.glob(f\"{destfolder}/*.mp4\")\n",
    "\n",
    "# DEEPLABCUT OVERLAY - CURRENTLY ONLY WORKING IN MY ENVIRONMENT. NEED TO CHECK VERSIONS\n",
    "\n",
    "# key = (model.VideoRecording & scan_key).fetch1('KEY')\n",
    "# key.update({'model_name': 'Head_orientation-NK', 'task_mode': 'trigger'})\n",
    "\n",
    "\n",
    "# from deeplabcut.utils.make_labeled_video import create_labeled_video\n",
    "# import yaml\n",
    "# from element_interface.utils import find_full_path\n",
    "# from adamacs.paths import get_dlc_root_data_dir\n",
    "\n",
    "\n",
    "# destfolder = model.PoseEstimationTask.infer_output_dir(scan_key)\n",
    "\n",
    "# config_paths = sorted( # Of configs in the project path, defer to the datajoint-saved\n",
    "#     list(\n",
    "#         find_full_path(\n",
    "#             get_dlc_root_data_dir(), ((model.Model & key).fetch1(\"project_path\"))\n",
    "#         ).glob(\"*.y*ml\")\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# create_labeled_video( # Pass strings to label the video\n",
    "#     config=str(config_paths[-1]),\n",
    "#     videos=str(topfile),\n",
    "#     destfolder=str(destfolder),\n",
    "# )\n",
    "\n",
    "\n",
    "# labeled_videofile = '/datajoint-data/data/tobiasr/RN_OPI-1681_2023-04-05_scan9FHELAYA_sess9FHELAYA/device_mini2p1_top_recording_scan9FHELAYA_model_Head_orientation-NK/scan9FHELAYA_top_video_2023-04-05T15_19_53DLC_resnet50_Head_orientationJul17shuffle1_90000_labeled.mp4'\n",
    "\n",
    "labeled_videodata = skvideo.io.vread(str(labeled_videofile[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load moving average registered Ca2+ imaging movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the registered moving average (blinking) movie data of the specified scanID\n",
    "\n",
    "scandir = (scan.ScanPath & scan_key).fetch('path')[0]\n",
    "\n",
    "directory = Path(scandir + \"/suite2p/plane0/reg_tif\")\n",
    "pattern = '*30_frame*.mp4'\n",
    "files = list(directory.glob(pattern))\n",
    "blinkvideodata = skvideo.io.vread(str(files[0]))\n",
    "blinkvideodata = np.asarray([skvideo.io.vshape(frame)[0] for frame in blinkvideodata], dtype=np.uint8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display camaravideo with slider\n",
    "sh.display_volume_z(videodata,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display 2pstackvideo with slider\n",
    "sh.display_volume_z(blinkvideodata,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display 2pstackvideo with slider\n",
    "sh.display_volume_z(labeled_videodata,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dimensionts of the original movie (frames, x,y,rgb)\n",
    "print(videodata.shape)\n",
    "print(blinkvideodata.shape)\n",
    "print(labeled_videodata.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synchronization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the timestamp data and gate / offset cameraframes\n",
    "\n",
    "# from the event table get the main recording gate start / end timestamps.\n",
    "auxgatetimestamp_end = (event.Event()  &  \"event_type='main_track_gate'\" &  scan_key ).fetch('event_end_time')\n",
    "auxgatetimestamp_start = (event.Event()  &  \"event_type='main_track_gate'\" &  scan_key ).fetch('event_start_time')\n",
    "\n",
    "# Then return camera start timestamps within the recording gate only \n",
    "cameratimestamps = (event.Event()  &  \"event_type='aux_cam'\" & f\"event_start_time>{auxgatetimestamp_start[0]}\" & f\"event_start_time<{auxgatetimestamp_end[0]}\" & scan_key).fetch('event_start_time')\n",
    "\n",
    "#  and 2p timestamps (which will always be in the recording gate).\n",
    "twoptimestamps = (event.Event()  &  \"event_type='mini2p_frames'\" &  scan_key ).fetch('event_start_time')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cameratimestamps.shape)\n",
    "print(twoptimestamps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twoptimestamps =  twoptimestamps[:np.shape(blinkvideodata)[0]] # truncating 2p timestamps to number of 2p videoframes\n",
    "\n",
    "#  Zero camera timestamps on first 2p timestamp. (not necessary)\n",
    "# cameratimestamps = cameratimestamps - twoptimestamps[0]\n",
    "# twoptimestamps = twoptimestamps - twoptimestamps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align the two recordings by finding the indices of the closest camera timestamp that fits the 2p frame timestamps by sorted list insertion (\"bisect\"). Be aware: camera frames can be double.\n",
    "aligned_cameraframes = get_closest_timestamps(twoptimestamps,cameratimestamps)\n",
    "\n",
    "# this should have the same shape as the 2p frames:\n",
    "print(np.shape(aligned_cameraframes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# now use this camara frame indices to reslice the video (which now is aligned to the 2p frames on a frame-by-frame level)\n",
    "# resliced_cam_video = videodata[aligned_cameraframes]\n",
    "resliced_cam_video = labeled_videodata[aligned_cameraframes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display synchronized movie\n",
    "sh.display_volume_z(resliced_cam_video,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale camera movie to fit size of 2p movie (can take a lot of time and memory)\n",
    "rescaled_cam_movie = resize_movie(resliced_cam_video, np.shape(blinkvideodata)[1],np.shape(blinkvideodata)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(rescaled_cam_movie)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate and display movies\n",
    "concatmovie = np.concatenate((blinkvideodata,rescaled_cam_movie), axis = 2)\n",
    "sh.display_volume_z(concatmovie,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as new movie (without rescaling)\n",
    "\n",
    "\n",
    "filename = str(directory) + '/aligned_stack_cam_movie.mp4'\n",
    "fps = (scan.ScanInfo & scan_key).fetch('fps')\n",
    "# p1 = 0\n",
    "# p2 = 100\n",
    "# trash = sh.make_stack_movie(concatmovie, filename, fps[0], p1, p2)\n",
    "\n",
    "codecset = 'libx264'\n",
    "import imageio\n",
    "import imageio.plugins.ffmpeg as ffmpeg\n",
    "\n",
    "# Create an imageio VideoWriter object to write the video\n",
    "writer = imageio.get_writer(filename, fps=fps[0], codec=codecset, output_params=['-crf', '19'])\n",
    "\n",
    "# # Calculate the 1st and 99th percentile\n",
    "# p1, p99 = np.percentile(running_z_projection[:500,:,:], (p1set, p2set))\n",
    "\n",
    "# # rescale to 8 bit\n",
    "# rescaled_image_8bit = rescale_image_multithreaded(running_z_projection, p1, p99)\n",
    "\n",
    "for page in concatmovie:\n",
    "    writer.append_data(page)\n",
    "\n",
    "# Close the video writer\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speed up, add timestamps etc - all with fast ffmpeg operations\n",
    "\n",
    "import os\n",
    "\n",
    "spedby = 5\n",
    "setpts_value = 1/spedby # change this to your desired value\n",
    "newfps = fps[0]*spedby\n",
    "\n",
    "input_filename = filename\n",
    "# 2. Add timestamps\n",
    "\n",
    "output_filename = str(directory) + '/' + scansi + '_top_video_concatenated' + 'withtimestamps.mp4'\n",
    "command = f\"\"\"ffmpeg -y -i {input_filename} -vf \"drawtext=fontfile=/Library/Fonts/Arial.ttf:timecode='00\\\\\\\\:00\\\\\\\\:00\\\\\\\\:00':rate={fps[0]}:text='':fontsize=12:fontcolor=white:x={np.shape(rescaled_cam_movie)[1]+10}:y=10:box=1:boxcolor=0x00000000@1\" -f mp4 {output_filename}\"\"\"\n",
    "\n",
    "os.system(command)\n",
    "\n",
    "\n",
    "input_filename = output_filename  # 'sped_up_video.mp4'\n",
    "output_filename = str(directory) + '/' +  scansi + '_top_video_concatenated_spedup_' + str(spedby) + 'fold_withtimestamps.mp4'\n",
    "\n",
    "command = f'ffmpeg -y -i {input_filename} -vf \"setpts={setpts_value}*PTS\" -r {newfps}  {output_filename}'\n",
    "\n",
    "\n",
    "\n",
    "os.system(command)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the fluorescence traces of this recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mask positions of masks that are classified as cells and that are larger than a certain pixel size\n",
    "mask_xpix, mask_ypix = (\n",
    "    imaging.Segmentation.Mask * imaging.MaskClassification.MaskType\n",
    "    & scan_key\n",
    "    & \"mask_npix > 30\"\n",
    "    & \"curation_id = 1\"\n",
    ").fetch(\"mask_xpix\", \"mask_ypix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this query, we've fetched the coordinates of segmented masks. We can overlay these\n",
    "masks onto our average image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_image = np.zeros(np.shape(average_image), dtype=bool)\n",
    "for xpix, ypix in zip(mask_xpix, mask_ypix):\n",
    "    mask_image[ypix, xpix] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image styles for display\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "mpl.rcParams.update(img_params)\n",
    "\n",
    "plt.imshow(average_image, cmap='gray', vmin = cmin, vmax = cmax)\n",
    "plt.contour(mask_image, colors=\"red\", linewidths=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different ROI visualization (colorful transparent overlay - more suite2p-like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Normalize the average_image to [0, 1]\n",
    "average_image = (average_image - average_image.min()) / (average_image.max() - average_image.min())\n",
    "# average_image = (max_proj_image - max_proj_image.min()) / (max_proj_image.max() - max_proj_image.min())\n",
    "# max_proj_image\n",
    "# Determine the number of masks\n",
    "num_masks = len(mask_xpix)\n",
    "\n",
    "# Generate random colormap using HSV\n",
    "np.random.seed(42)  # For reproducibility, remove this line for truly random colors every time\n",
    "hues = np.random.rand(num_masks)\n",
    "colors = [mcolors.hsv_to_rgb([hue, 1, 1]) for hue in hues]\n",
    "\n",
    "# # Create a color overlay using a perceptually uniform colormap\n",
    "# colormap = plt.cm.viridis  # You can also use 'plasma', 'cividis', etc.\n",
    "# colors = [colormap(i) for i in np.linspace(0, 1, num_masks)]\n",
    "\n",
    "\n",
    "# Start with the grayscale image as the base\n",
    "color_overlay = np.repeat(average_image[..., np.newaxis], 3, axis=2)\n",
    "\n",
    "# Define an alpha factor for overall translucency (e.g., 0.5 for 50% transparency)\n",
    "alpha_factor = 0.2\n",
    "\n",
    "# Loop through masks, add color overlays\n",
    "for (xpix, ypix), color in zip(zip(mask_xpix, mask_ypix), colors):\n",
    "    for i in range(3):  # R, G, B channels\n",
    "        color_overlay[ypix, xpix, i] = color_overlay[ypix, xpix, i] * (1 - alpha_factor) + color[i] * alpha_factor\n",
    "\n",
    "# Display using Matplotlib\n",
    "plt.imshow(color_overlay)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more example using queries - plot fluorescence and deconvolved activity\n",
    "traces:\n",
    "\n",
    "Here we fetch the primary key attributes of the entry with `curation_id=0` for the\n",
    "current session in the `imaging.Curation` table. \n",
    "\n",
    "Then, we fetch all cells that fit the\n",
    "restriction criteria from `imaging.Segmentation.Mask` and\n",
    "`imaging.MaskClassification.MaskType` as a `projection`. \n",
    "\n",
    "We then use this projection as\n",
    "a restriction to fetch and plot fluorescence and deconvolved activity traces from the\n",
    "`imaging.Fluorescence.Trace` and `imaging.Activity.Trace` tables, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curation_key = (imaging.Curation & scan_key & \"curation_id=1\").fetch1(\"KEY\")\n",
    "query_cells = (\n",
    "    imaging.Segmentation.Mask * imaging.MaskClassification.MaskType\n",
    "    & curation_key\n",
    "    & \"mask_center_z=0\"\n",
    "    & \"mask_npix > 30\"\n",
    ").proj()\n",
    "\n",
    "# query_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuropilcorr = True\n",
    "\n",
    "fluorescence_traces = (imaging.Fluorescence.Trace & query_cells).fetch(\n",
    "    \"fluorescence\", order_by=\"mask\"\n",
    ")\n",
    "\n",
    "neuropil_traces = (imaging.Fluorescence.Trace & query_cells).fetch(\n",
    "    \"neuropil_fluorescence\", order_by=\"mask\"\n",
    ")\n",
    "\n",
    "if neuropilcorr:\n",
    "    print(\"DOING VANILLA NEUROPIL CORRECTION NOW!\")\n",
    "    fluorescence_traces = fluorescence_traces - 0.7 * neuropil_traces\n",
    "\n",
    "activity_traces = (imaging.Activity.Trace & query_cells).fetch(\n",
    "    \"activity_trace\", order_by=\"mask\"\n",
    ")\n",
    "\n",
    "sampling_rate = (scan.ScanInfo & curation_key).fetch1(\"fps\")\n",
    "\n",
    "# timebase_2p = np.r_[: fluorescence_traces[0].size] * 1 / sampling_rate\n",
    "\n",
    "timebase_2p = np.linspace(0, fluorescence_traces[0].size / sampling_rate, fluorescence_traces[0].shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rastermap import Rastermap\n",
    "from scipy import stats \n",
    "from scipy.stats import zscore\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "# stack fluorescence for rastermap\n",
    "fluos = np.vstack(fluorescence_traces)\n",
    "\n",
    "nan_mask = np.isnan(fluos).any(axis=1)\n",
    "\n",
    "# Create a mask for rows containing only zeros\n",
    "zero_rows = np.all(fluos == 0, axis=1)\n",
    "\n",
    "# Create a mask for rows containing only inf\n",
    "inf_rows = np.all(np.isinf(fluos), axis=1)\n",
    "\n",
    "# Create a mask for rows containing only NaN\n",
    "nan_rows = np.all(np.isnan(fluos), axis=1)\n",
    "\n",
    "# Combine the masks using logical OR\n",
    "mask_to_remove = zero_rows | inf_rows | nan_rows | nan_mask\n",
    "\n",
    "S = fluos[~mask_to_remove]\n",
    "S = zscore(S, axis=1)\n",
    "\n",
    "rmmodel = Rastermap(n_clusters=100, # None turns off clustering and sorts single neurons \n",
    "                  n_PCs=10, # use fewer PCs than neurons\n",
    "                  locality=0.15, # some locality in sorting (this is a value from 0-1)\n",
    "                  time_lag_window=15, # use future timepoints to compute correlation\n",
    "                  grid_upsample=0, # 0 turns off upsampling since we're using single neurons\n",
    "                ).fit(S)\n",
    "\n",
    "\n",
    "y = rmmodel.embedding # neurons x 1\n",
    "isort = rmmodel.isort\n",
    "\n",
    "# sort by embedding and smooth over neurons (uncomment)\n",
    "\n",
    "# Sfilt = gaussian_filter1d(S[isort], np.minimum(1,np.maximum(1,int(S.shape[0]*0.001))),axis=0)\n",
    "Sfilt = S[isort]\n",
    "Sfilt_backup = Sfilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sorted data\n",
    "# load plot styles for display\n",
    "\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "mpl.rcParams.update(plot_params)\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.imshow(Sfilt, vmin = -0.1, vmax=0.5, extent= [timebase_2p[0], timebase_2p[-1], 0, Sfilt.shape[0]], aspect='auto', cmap='gray_r')\n",
    "plt.xlabel('time [s]')\n",
    "plt.ylabel('sorted neurons')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "figure = plt.figure(figsize=(15,15))\n",
    "ax = figure.add_subplot(111)\n",
    "\n",
    "offset_scaler = 10 # We want to plot every cell with a little offset to the last one\n",
    "for no,trace in enumerate(Sfilt):\n",
    "    # if no == 25: break # not more than 80\n",
    "\n",
    "    # get the neuropil corrected values for that trace:\n",
    "    # trace = Sfilt\n",
    "    ax.plot(timebase_2p,trace + (no*offset_scaler),lw=1,c='k',alpha=.8)\n",
    "\n",
    "ax.set_xlim(0,timebase_2p[-1])\n",
    "\n",
    "ax.get_yaxis().set_ticks([])\n",
    "ax.set_title('Sorted z-scored traces')    \n",
    "\n",
    "ax.set_ylabel('Cells')\n",
    "ax.set_xlabel('Time [s]')\n",
    "sns.despine(left=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binarized event visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from scipy.ndimage import binary_dilation\n",
    "\n",
    "\n",
    "method = \"tank\"\n",
    "# method = \"sd\"\n",
    "# method = \"poor\"\n",
    "\n",
    "cutoff_std = float(3)\n",
    "min_transient_length = .3\n",
    "\n",
    "filtered_event_mask = []\n",
    "\n",
    "for cell in range(len(activity_traces)):  \n",
    "    # Horst's event filtering \n",
    "    re = th.FilterEvents(activity_traces[cell])\n",
    "    if method == \"tank\":\n",
    "        transient_dict = re.transients(fluorescence_traces[cell],\n",
    "                    np.ones_like(fluorescence_traces[cell], dtype=bool),\n",
    "                    sampling_rate, cutoff_std, min_transient_length, plot=False)\n",
    "    elif method == \"sd\":\n",
    "        transient_dict = re.robust(cutoff_std)  \n",
    "    filtered_event_mask.append(transient_dict['mask_events'])\n",
    "\n",
    "event_matrix = np.array(filtered_event_mask)\n",
    "\n",
    "\n",
    "if method == \"poor\":\n",
    "    event_matrix = np.array([item > cutoff_std for item in Sfilt], dtype=bool).astype(int)\n",
    "\n",
    "\n",
    "# broaden events to generate non-event baseline for SNR calculation and second pass event detection with proper f0 baseline\n",
    "\n",
    "cutoff_std = float(2)\n",
    "min_transient_length = .250 # s\n",
    "\n",
    "broaden_by = 1 # s\n",
    "\n",
    "# Structuring element for one-second dilation\n",
    "structure = np.ones(int(broaden_by * sampling_rate))\n",
    "\n",
    "filtered_event_mask_2ndpass =[]\n",
    "broadened_events = []\n",
    "filtered_events = []\n",
    "SNR = []\n",
    "dFF0_traces = []\n",
    "\n",
    "if method == \"tank\":\n",
    "    for cell in range(len(activity_traces)):\n",
    "        re = th.FilterEvents(activity_traces[cell])\n",
    "        \n",
    "        # make dF/F0 from first pass events\n",
    "        F0mean = np.mean(fluorescence_traces[cell][np.logical_not(event_matrix[cell])])\n",
    "        dFF0 = (fluorescence_traces[cell] - F0mean) / F0mean\n",
    "        \n",
    "        # Apply binary dilation on previous events and invert to get baseline\n",
    "        \n",
    "        broadened_events = binary_dilation(filtered_event_mask[cell], structure=structure) \n",
    "        \n",
    "        transient_dict = re.transients(dFF0,\n",
    "                    np.logical_not(broadened_events),\n",
    "                    sampling_rate, cutoff_std, min_transient_length, plot=False)\n",
    " \n",
    "        filtered_event_mask_2ndpass.append(transient_dict['mask_events'])\n",
    "        filtered_events.append(transient_dict['filtered_events'])      \n",
    "        \n",
    "        SNR.append(np.mean(filtered_events[cell] / np.nanstd(dFF0[np.logical_not(broadened_events)])))\n",
    "        dFF0_traces.append(dFF0)\n",
    "        \n",
    "    event_matrix_2ndpass = np.array(filtered_event_mask_2ndpass)\n",
    "\n",
    "\n",
    "\n",
    "# sort events based on previous rastermap embedding\n",
    "event_matrix = event_matrix[isort]\n",
    "event_matrix_2ndpass = event_matrix_2ndpass[isort]\n",
    "dFF0_traces = np.array(dFF0_traces)[isort]\n",
    "\n",
    "\n",
    "# plot events and non-event epochs (with traces)\n",
    "\n",
    "figure = plt.figure(figsize=(15,20))\n",
    "ax = figure.add_subplot(111)\n",
    "\n",
    "\n",
    "offset_scaler = 1.5 # We want to plot every cell with a little offset to the last one\n",
    "for no, (trace, trace2) in enumerate(zip(event_matrix, event_matrix_2ndpass)):\n",
    "    if no == 80: break # not more than 80\n",
    "\n",
    "    ax.plot(timebase_2p, trace + (no * offset_scaler), lw=1, c='k', alpha=.8)\n",
    "    ax.plot(timebase_2p, trace2 + (no * offset_scaler), lw=2, c='r', alpha=.8)\n",
    "\n",
    "\n",
    "ax.set_xlim(0,timebase_2p[-1])\n",
    "\n",
    "ax.get_yaxis().set_ticks([])\n",
    "ax.set_title('Sorted binarized deconvolved traces')    \n",
    "\n",
    "ax.set_ylabel('Cells')\n",
    "ax.set_xlabel('Time [s]')\n",
    "sns.despine(left=True)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#set used event_matrix\n",
    "event_matrix = event_matrix_2ndpass\n",
    "SNR_matrix = np.array(SNR)[isort]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "figure = plt.figure(figsize=(15,15))\n",
    "ax = figure.add_subplot(111)\n",
    "\n",
    "SNRthresh = 0.4\n",
    "\n",
    "offset_scaler = 8 # We want to plot every cell with a little offset to the last one\n",
    "for no, (trace,evnts) in enumerate(zip(dFF0_traces[SNR_matrix > SNRthresh,:], event_matrix[SNR_matrix > SNRthresh,:] * 1)):\n",
    "    if no == 15: break # not more than 25\n",
    "\n",
    "    # get the neuropil corrected values for that trace:\n",
    "    # trace = Sfilt\n",
    "    ax.plot(timebase_2p,trace + (no*offset_scaler),lw=1,c='k',alpha=.8)\n",
    "    ax.plot(timebase_2p, evnts + (no*offset_scaler - 1.4),lw=2,c='r',alpha=.8)\n",
    "\n",
    "ax.set_xlim(0,timebase_2p[-1])\n",
    "\n",
    "ax.get_yaxis().set_ticks([])\n",
    "ax.set_title('Sorted, SNR-filtered dF/F0 traces')    \n",
    "\n",
    "ax.set_ylabel('Cells')\n",
    "ax.set_xlabel('Time [s]')\n",
    "sns.despine(left=True)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit data to SNR threshold from hereon\n",
    "Sfilt = Sfilt_backup[SNR_matrix > SNRthresh]\n",
    "event_matrix = event_matrix[SNR_matrix > SNRthresh]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synchronization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the timestamp data and gate / offset cameraframes\n",
    "\n",
    "# from the event table get the main recording gate start / end timestamps.\n",
    "auxgatetimestamp_end = (event.Event()  &  \"event_type='main_track_gate'\" &  scan_key ).fetch('event_end_time')\n",
    "auxgatetimestamp_start = (event.Event()  &  \"event_type='main_track_gate'\" &  scan_key ).fetch('event_start_time')\n",
    "\n",
    "# Then return camera start timestamps within the recording gate only \n",
    "cameratimestamps = (event.Event()  &  \"event_type='aux_cam'\" & f\"event_start_time>{auxgatetimestamp_start[0]}\" & f\"event_start_time<{auxgatetimestamp_end[0]}\" & scan_key).fetch('event_start_time')\n",
    "\n",
    "#  and 2p timestamps (which will always be in the recording gate).\n",
    "twoptimestamps = (event.Event()  &  \"event_type='mini2p_frames'\" &  scan_key ).fetch('event_start_time')\n",
    "\n",
    "# align the two recordings by finding the indices of the closest camera timestamp that fits the 2p frame timestamps by sorted list insertion (\"bisect\"). Be aware: camera frames can be double.\n",
    "aligned_cameraframes = get_closest_timestamps(twoptimestamps,cameratimestamps)\n",
    "\n",
    "# this should have the same shape as the 2p frames:\n",
    "print(np.shape(aligned_cameraframes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the timestamps of the video synchronization from above are the one to use for synchronized plotting of positions etc: aligned_cameraframes\n",
    "print(np.shape(cameratimestamps))\n",
    "print(np.shape(aligned_cameraframes))\n",
    "print(np.shape(twoptimestamps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now do some positional plotting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc_scan_key = (model.PoseEstimation & f'recording_id = \"{scan_key[\"scan_id\"]}\"').fetch('KEY')[0] \n",
    "path = (model.VideoRecording.File & scan_key).fetch(\"file_path\")\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc_scan_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce dataframe to xy coordinates\n",
    "\n",
    "df=model.PoseEstimation.get_trajectory(dlc_scan_key)\n",
    "df_xy = df.iloc[:,df.columns.get_level_values(2).isin([\"x\",\"y\"])]['Head_orientation-NK']\n",
    "# df_xy.mean()\n",
    "# df_xy\n",
    "df_xy.plot().legend(loc='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flat = df_xy.copy()\n",
    "df_flat.columns = df_flat.columns.map('_'.join)\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "df_flat.plot(x='body_middle_x',y='body_middle_y',ax=ax)\n",
    "df_flat.plot(x='head_middle_x',y='head_middle_y', ax=ax)\n",
    "df_flat.plot(x='tail_x',y='tail_y', ax=ax)\n",
    "ax.set_aspect('equal')\n",
    "plt.title(scan_key)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot events over position\n",
    "\n",
    "position = df_flat[['body_middle_x', 'body_middle_y']].values\n",
    "position = position[aligned_cameraframes].T/10 # synchronize to 2pframes and translate for opexebo - THIS IS A GUESSTIMATE!  pretending 1px = 1mm NEEDS CALIBRATION - tracking needs to be in xy real-world coordinates (in cm)\n",
    "\n",
    "\n",
    "total_cells = np.shape(event_matrix)[0] # Change this to the desired number of cells\n",
    "\n",
    "# Determine the grid dimensions (for a roughly square arrangement)\n",
    "nrows = int(np.ceil(np.sqrt(total_cells)))\n",
    "ncols = int(np.ceil(total_cells / nrows))\n",
    "\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(30, 30))\n",
    "fig.subplots_adjust(hspace=0.1) # Add some space between the subplots\n",
    "\n",
    "# If axs is not already a 2D array (e.g., if total_cells is a perfect square), make it one\n",
    "if total_cells != nrows * ncols:\n",
    "    axs = axs.reshape(-1)\n",
    "\n",
    "# load image styles for display\n",
    "# load image styles for display\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "mpl.rcParams.update(map_params)\n",
    "\n",
    "for cell in range(total_cells):\n",
    "    # try:    \n",
    "    ax = axs[cell]\n",
    "    # Plotting the line plot first\n",
    "    ax.plot(position[0], position[1], color='grey')\n",
    "\n",
    "    # spike events at position\n",
    "    spikes_at_pos = np.vstack((position[0, event_matrix[cell].astype(\"bool\")], position[1, event_matrix[cell].astype(\"bool\")]))\n",
    "    \n",
    "    # Then plotting the scatter plot so that it's on top of the line\n",
    "    ax.scatter(spikes_at_pos[0], spikes_at_pos[1], color='red', alpha = 0.2, zorder=2)\n",
    "\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title(scan_key[\"scan_id\"] + \"_\" + str(cell+1))\n",
    "    # except:\n",
    "    #     print(f'error at cell{cell}')\n",
    "# Remove any extra subplots\n",
    "for cell in range(total_cells, nrows * ncols):\n",
    "    fig.delaxes(axs[cell])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make masked spatial occupancy map - OPEXEBO\n",
    "\n",
    "import opexebo\n",
    "\n",
    "arena_size = 100 # in cm - NEEDS CALIBRATED TRACKING COORDS!\n",
    "arena_shape = \"circle\"\n",
    "bin_width =  4 # cm\n",
    "\n",
    "masked_occupancy_map, coverage, bin_edges = opexebo.analysis.spatial_occupancy(timebase_2p, position, arena_size, arena_shape = arena_shape, bin_width = bin_width)\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.imshow(np.flipud(masked_occupancy_map))\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('time / bin [s]')\n",
    "plt.title(f'spatial occupancy - {scan_key[\"scan_id\"]}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot rate maps - OPEXEBO\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "\n",
    "# Determine the grid dimensions (for a roughly square arrangement)\n",
    "nrows = int(np.ceil(np.sqrt(total_cells)))\n",
    "ncols = int(np.ceil(total_cells / nrows))\n",
    "\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(30, 30))\n",
    "fig.subplots_adjust(hspace=0.1) # Add some space between the subplots\n",
    "\n",
    "# If axs is not already a 2D array (e.g., if total_cells is a perfect square), make it one\n",
    "if total_cells != nrows * ncols:\n",
    "    axs = axs.reshape(-1)\n",
    "\n",
    "# load image styles for display\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "mpl.rcParams.update(map_params)\n",
    "\n",
    "for cell in range(total_cells):\n",
    "    ax = axs[cell]\n",
    "    # print(cell)\n",
    "    try:\n",
    "        # spike events at position\n",
    "        spikes_at_pos = np.vstack((position[0, event_matrix[cell].astype(\"bool\")], position[1, event_matrix[cell].astype(\"bool\")]))\n",
    "        \n",
    "        # time at postiion\n",
    "        time_at_pos = (timebase_2p[event_matrix[cell].astype(\"bool\")])\n",
    "        \n",
    "        # spikes_tracking [t,x,y]\n",
    "        spikes_tracking = np.vstack((time_at_pos, spikes_at_pos))\n",
    "        \n",
    "        # make ratemap\n",
    "        rate_map = opexebo.analysis.rate_map(masked_occupancy_map, spikes_tracking, arena_size, arena_shape = arena_shape, bin_width = bin_width)\n",
    "        rate_map = np.flipud(rate_map)\n",
    "        # filtered_rate_map = gaussian_filter(rate_map, sigma = 0.5)\n",
    "        \n",
    "        \n",
    "        # Then plotting the scatter plot so that it's on top of the line\n",
    "        im = ax.imshow(rate_map, vmin = 0, vmax = 2)\n",
    "\n",
    "        ax.set_aspect('equal')\n",
    "        ax.set_title(scan_key[\"scan_id\"] + \"-\" + str(cell+1))\n",
    "        # cbar = plt.colorbar(im, ax=ax) # Pass the image object and the ax to plt.colorbar\n",
    "        # cbar.set_label('events / bin [s]')\n",
    "    except:\n",
    "        print(f'error at cell{cell}')\n",
    "\n",
    "# Remove any extra subplots\n",
    "for cell in range(total_cells, nrows * ncols):\n",
    "    fig.delaxes(axs[cell])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### speed tuning - freely moving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get running speed - OPEXEBO\n",
    "new_speed = opexebo.analysis.calc_speed(timebase_2p, position[0], position[1], moving_average = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "mpl.rcParams.update(plot_params)\n",
    "\n",
    "# get some scaling values from pixel distribution\n",
    "scalemin = 0\n",
    "scalemax = 99.7\n",
    "\n",
    "cmin = np.percentile(new_speed,scalemin)  \n",
    "cmax = np.percentile(new_speed,scalemax)\n",
    "\n",
    "kp_colors = np.array([[0.55,0.55,0.55]])\n",
    "\n",
    "\n",
    "# timepoints to visualize\n",
    "tstart = 0\n",
    "tend =  timebase_2p[-1] - 1\n",
    "\n",
    "xmin = int(np.floor(tstart * sampling_rate))\n",
    "xmax = int(np.floor(tend * sampling_rate))\n",
    "\n",
    "# make figure with grid for easy plotting\n",
    "fig = plt.figure(figsize=(8,5), dpi=200)\n",
    "grid = plt.GridSpec(9, 20, figure=fig, wspace = 0.05, hspace = 0.3)\n",
    "\n",
    "# plot running speed\n",
    "ax = plt.subplot(grid[:2, :-1])\n",
    "ax.plot(new_speed,  color=kp_colors[0])\n",
    "ax.set_xlim([0, xmax-xmin])\n",
    "ax.set_ylim([cmin, cmax])\n",
    "\n",
    "ax.axis(\"off\")\n",
    "ax.set_title(\"freely moving running speed\", color=kp_colors[0])\n",
    "# ax.set_xlabel(\"running speed\")\n",
    "\n",
    "\n",
    "# plot superneuron activity\n",
    "ax = plt.subplot(grid[2:, :-1])\n",
    "ax.imshow(Sfilt[:, xmin:xmax], cmap=\"gray_r\", vmin=-0.1, vmax=0.7,  extent= [timebase_2p[xmin], timebase_2p[xmax], 0, Sfilt.shape[0]], aspect=\"auto\")\n",
    "ax.set_xlabel(\"time [s]\")\n",
    "ax.set_ylabel(\"sorted, SNR-filtered cells [z]\")\n",
    "\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.show()\n",
    "\n",
    "# ax = plt.subplot(grid[1:, -1])\n",
    "# ax.imshow(np.arange(0, len(sn))[:,np.newaxis], cmap=\"gist_ncar\", aspect=\"auto\")\n",
    "# ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET IMU data\n",
    "\n",
    "accelerometer = (behavior.HarpRecording.Channel() & scan_key & \"channel_name LIKE 'IMU accelerometer %'\").fetch(\"data\")\n",
    "gyroscope = (behavior.HarpRecording.Channel() & scan_key & \"channel_name LIKE 'IMU gyroscope %'\").fetch(\"data\")\n",
    "magnetometer = (behavior.HarpRecording.Channel() & scan_key & \"channel_name LIKE 'IMU magnetometer %'\").fetch(\"data\")\n",
    "IMU_twopframes = (behavior.HarpRecording.Channel() & scan_key & \"channel_name LIKE '2p %'\").fetch(\"data\")\n",
    "IMU_time = (behavior.HarpRecording.Channel() & scan_key & \"channel_name LIKE '2p %'\").fetch(\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SYNC IMU data\n",
    "\n",
    "propersync = np.max(IMU_twopframes[0]).astype(\"bool\")\n",
    "\n",
    "## Get the timestamp data\n",
    "\n",
    "# from the event table get the main recording gate start / end HARP gate timestamps.\n",
    "harpgatetimestamp_end = (event.Event()  &  \"event_type='HARP_gate'\" &  scan_key ).fetch('event_end_time')\n",
    "harpgatetimestamp_start = (event.Event()  &  \"event_type='HARP_gate'\" &  scan_key ).fetch('event_start_time')\n",
    "\n",
    "if propersync:\n",
    "    print(\"2p timestamps detected\")\n",
    "else:\n",
    "    print(\"No 2p timestamps in IMU rec detected - poor man's single-point sync\")\n",
    "    IMU_time = IMU_time - harpgatetimestamp_start\n",
    "    # HARP and AUX not in sync!\n",
    "    print(IMU_time[0][-1]/1000)  \n",
    "    print(harpgatetimestamp_end[0])\n",
    "\n",
    "    # Therefore: space number of HARP samples evenly between HARP gate timestampa.\n",
    "    harpgate_sync_timestamps = np.squeeze(np.linspace(harpgatetimestamp_start, harpgatetimestamp_end, np.shape(magnetometer[0])[0]))\n",
    "    \n",
    "#  and 2p timestamps (which will always be in the recording gate).\n",
    "twoptimestamps = (event.Event()  &  \"event_type='mini2p_frames'\" &  scan_key ).fetch('event_start_time')\n",
    "\n",
    "\n",
    "# get indices\n",
    "aligned_IMU_indices = get_closest_timestamps(twoptimestamps,harpgate_sync_timestamps) #smoothing windwo from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter IMU data\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "# Design the Butterworth filter\n",
    "N = 6 # Order of the filter\n",
    "Wn = 0.03 # Cutoff frequency (example value, should be chosen based on your specific needs)\n",
    "b, a = butter(N, Wn, btype='low')\n",
    "\n",
    "# Design the Butterworth filter\n",
    "N = 6 # Order of the filter\n",
    "Wn = 0.005 # Cutoff frequency (example value, should be chosen based on your specific needs)\n",
    "c, d = butter(N, Wn, btype='low')\n",
    "\n",
    "filtered_accelerometer = [lfilter(b, a, array) for array in accelerometer]\n",
    "filtered_gyroscope = [lfilter(c, d, array) for array in gyroscope]\n",
    "filtered_magnetometer = [lfilter(b, a, array) for array in magnetometer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate event trace for light stim\n",
    "\n",
    "# from the event table get the main recording gate start / end HARP gate timestamps.\n",
    "flash_timestamp_end = (event.Event()  &  \"event_type='arena_LED'\" &  scan_key ).fetch('event_end_time')\n",
    "flash_timestamp_start = (event.Event()  &  \"event_type='arena_LED'\" &  scan_key ).fetch('event_start_time')\n",
    "twoptimestamps = (event.Event()  &  \"event_type='mini2p_frames'\" &  scan_key ).fetch('event_start_time')\n",
    "\n",
    "# get indices\n",
    "aligned_flash_timestamp_end  = get_closest_timestamps(flash_timestamp_end, twoptimestamps) #smoothing windwo from above\n",
    "aligned_flash_timestamp_start  = get_closest_timestamps(flash_timestamp_start, twoptimestamps) #smoothing windwo from above\n",
    "\n",
    "# Create a linear array of zeros of length 10\n",
    "array_length = np.shape(twoptimestamps)[0]\n",
    "flash_array = np.zeros(array_length)\n",
    "\n",
    "# Iterate through the start and stop times and set the corresponding elements to 1\n",
    "for start, stop in zip(aligned_flash_timestamp_start, aligned_flash_timestamp_end):\n",
    "    flash_array[start:stop] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "mpl.rcParams.update(plot_params)\n",
    "\n",
    "# get some scaling values from pixel distribution\n",
    "# SPEED \n",
    "scalemin = 0\n",
    "scalemax = 99.7\n",
    "\n",
    "cmin = np.percentile(new_speed,scalemin)  \n",
    "cmax = np.percentile(new_speed,scalemax)\n",
    "\n",
    "# ACC \n",
    "scalemin = 0\n",
    "scalemax = 100\n",
    "\n",
    "acc_cmin = np.percentile(np.concatenate(filtered_accelerometer),scalemin)  \n",
    "acc_cmax = np.percentile(np.concatenate(filtered_accelerometer),scalemax)\n",
    "\n",
    "# GYR \n",
    "scalemin = 0\n",
    "scalemax = 100\n",
    "\n",
    "gyr_cmin = np.percentile(np.concatenate(filtered_gyroscope),scalemin)  \n",
    "gyr_cmax = np.percentile(np.concatenate(filtered_gyroscope),scalemax)\n",
    "\n",
    "# MAG \n",
    "scalemin = 0\n",
    "scalemax = 100\n",
    "\n",
    "mag_cmin = np.percentile(np.concatenate(filtered_magnetometer),scalemin)  \n",
    "mag_cmax = np.percentile(np.concatenate(filtered_magnetometer),scalemax)\n",
    "\n",
    "\n",
    "kp_colors = np.array([[0,0,0], [0.55,0.55,0.55], [0,0.9,0.9]])\n",
    "\n",
    "imu_colors = np.array([\n",
    "    [[1.0, 0.75, 0.8], [0.8, 0.65, 0.68], [0.55, 0.55, 0.55]],\n",
    "    [[0.95, 0.6, 0.95], [0.75, 0.58, 0.75], [0.55, 0.55, 0.55]],\n",
    "    [[0.65, 0.95, 0.95], [0.6, 0.75, 0.75], [0.55, 0.55, 0.55]]\n",
    "])\n",
    "\n",
    "# timepoints to visualize\n",
    "tstart = 0\n",
    "tend =  timebase_2p[-1] -1\n",
    "\n",
    "xmin = int(np.floor(tstart * sampling_rate))\n",
    "xmax = int(np.floor(tend * sampling_rate))\n",
    "\n",
    "# make figure with grid for easy plotting\n",
    "fig = plt.figure(figsize=(20,10), dpi = 200)\n",
    "grid = plt.GridSpec(20, 20, figure=fig, wspace = 0.5, hspace = 0.3)\n",
    "\n",
    "# plot running speed\n",
    "ax = plt.subplot(grid[:2, :-1])\n",
    "ax.plot(new_speed,  color=kp_colors[0])\n",
    "ax.set_xlim([0, xmax-xmin])\n",
    "ax.set_ylim([cmin, cmax])\n",
    "ax.tick_params(left=False, right=False, bottom=False, top=False,\n",
    "               labelleft=False, labelbottom=False)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_visible(False)\n",
    "ax.set_ylabel(\"speed\")\n",
    "ax.yaxis.set_label_position(\"left\")\n",
    "\n",
    "# ax.set_title(\"freely moving running speed\", color=kp_colors[0])\n",
    "# ax.set_xlabel(\"running speed\")\n",
    "\n",
    "# plot accelerometer\n",
    "sliced_accelerometer = [array[aligned_IMU_indices] for array in filtered_accelerometer]\n",
    "ax = plt.subplot(grid[2:4, :-1])\n",
    "for i, arr in enumerate(sliced_accelerometer):\n",
    "    ax.plot(arr, label=f'accelerometer {i+1}', color=imu_colors[0][i])\n",
    "ax.set_xlim([0, xmax-xmin])\n",
    "ax.set_ylim([acc_cmin, acc_cmax])\n",
    "ax.tick_params(left=False, right=False, bottom=False, top=False,\n",
    "               labelleft=False, labelbottom=False)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_visible(False)\n",
    "ax.set_ylabel(\"acc\")\n",
    "ax.yaxis.set_label_position(\"left\")\n",
    "\n",
    "# ax.set_title(\"freely moving running speed\", color=kp_colors[0])\n",
    "# ax.set_xlabel(\"running speed\")\n",
    "\n",
    "# plot gyroscope\n",
    "sliced_gyroscope = [array[aligned_IMU_indices] for array in filtered_gyroscope]\n",
    "ax = plt.subplot(grid[4:6, :-1])\n",
    "for i, arr in enumerate(sliced_gyroscope):\n",
    "    ax.plot(arr, label=f'gyroscope {i+1}', color=imu_colors[1][i])\n",
    "ax.set_xlim([0, xmax-xmin])\n",
    "ax.set_ylim([gyr_cmin, gyr_cmax])\n",
    "ax.tick_params(left=False, right=False, bottom=False, top=False,\n",
    "               labelleft=False, labelbottom=False)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_visible(False)\n",
    "ax.set_ylabel(\"gyr\")\n",
    "ax.yaxis.set_label_position(\"left\")\n",
    "\n",
    "# plot magnetometer\n",
    "sliced_magnetometer= [array[aligned_IMU_indices] for array in filtered_magnetometer]\n",
    "ax = plt.subplot(grid[6:8, :-1])\n",
    "for i, arr in enumerate(sliced_magnetometer):\n",
    "    ax.plot(arr, label=f'magnetometer {i+1}', color=imu_colors[2][i])\n",
    "ax.set_xlim([0, xmax-xmin])\n",
    "ax.set_ylim([mag_cmin, mag_cmax])\n",
    "ax.tick_params(left=False, right=False, bottom=False, top=False,\n",
    "               labelleft=False, labelbottom=False)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_visible(False)\n",
    "ax.set_ylabel(\"mag\")\n",
    "ax.yaxis.set_label_position(\"left\")\n",
    "# ax.set_title(\"freely moving running speed\", color=kp_colors[0])\n",
    "# ax.set_xlabel(\"running speed\")\n",
    "\n",
    "# # plot LIGHT flash\n",
    "# ax = plt.subplot(grid[8:10, :-1])\n",
    "# ax.plot(flash_array,  color=kp_colors[1])\n",
    "# ax.set_xlim([0, xmax-xmin])\n",
    "# ax.set_ylim([-.1, 1.1])\n",
    "# ax.tick_params(left=False, right=False, bottom=False, top=False,\n",
    "#                labelleft=False, labelbottom=False)\n",
    "# for spine in ax.spines.values():\n",
    "#     spine.set_visible(False)\n",
    "# ax.set_ylabel(\"flash\")\n",
    "# ax.yaxis.set_label_position(\"left\")\n",
    "\n",
    "# plot neuronal activity\n",
    "ax = plt.subplot(grid[8:, :-1])\n",
    "ax.imshow(Sfilt[:, xmin:xmax], cmap=\"gray_r\", vmin=0, vmax=1.2,  extent= [timebase_2p[xmin], timebase_2p[xmax], 0, Sfilt.shape[0]], aspect=\"auto\")\n",
    "ax.set_xlabel(\"time [s]\")\n",
    "ax.set_ylabel(\"sorted, SNR - filtered cells [z]\")\n",
    "\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.show()\n",
    "\n",
    "# ax = plt.subplot(grid[1:, -1])\n",
    "# ax.imshow(np.arange(0, len(sn))[:,np.newaxis], cmap=\"gist_ncar\", aspect=\"auto\")\n",
    "# ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better event handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datajoint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
